{"meta":{"title":"SDN BOLG","subtitle":"","description":"","author":"Simonck","url":"http://example.com","root":"/"},"pages":[{"title":"分类","date":"2022-08-09T08:05:36.000Z","updated":"2022-08-09T08:06:51.099Z","comments":true,"path":"categories/index.html","permalink":"http://example.com/categories/index.html","excerpt":"","text":""},{"title":"标签","date":"2022-08-09T08:05:27.000Z","updated":"2022-08-09T08:07:11.738Z","comments":true,"path":"tags/index.html","permalink":"http://example.com/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"拓扑发现功能梳理","slug":"拓扑发现功能梳理","date":"2022-10-14T13:03:38.329Z","updated":"2022-10-14T08:40:04.525Z","comments":true,"path":"2022/10/14/拓扑发现功能梳理/","link":"","permalink":"http://example.com/2022/10/14/%E6%8B%93%E6%89%91%E5%8F%91%E7%8E%B0%E5%8A%9F%E8%83%BD%E6%A2%B3%E7%90%86/","excerpt":"​ 本文记录拓扑发现功能的设计原理。","text":"​ 本文记录拓扑发现功能的设计原理。 拓扑分层​ 目前机动通信系统的拓扑可以视为由三层拓扑组成，如下图所示，拓扑发现功能的实现，既有ODL本身项目提供的内容，又有私有开发的内容。 拓扑层次 对应功能模块 拓扑类别 主机与交换机的连接 Host tracker 车内拓扑 内网交换机、外网交换机的连接 ICDP(LLDP) 车内拓扑 节点与节点的连接 ICSP(OSPF) 车外拓扑 主机与交换机的连接​ 这部分拓扑发现结果由Host tracker模块提供，实现原理参见L2switch.md，实现过程参见SDN开发日志.md。 内网交换机、外网交换机的连接​ 这部分对应传统网络中的链路层拓扑发现，核心原理是LLDP协议，ODL、NOX等控制器对该协议进行了移植(OFDP算法),使其能够运行在SDN网络上,ODL代码主要在openflowplugin项目中. 参考文献 曾干.基于链路层发现协议(LLDP)的物理网络拓扑发现[J].电脑知识与技术,2006(20):45-46+48. LLDP概要介绍 实现原理​ 目前对这部分实现的主体是openflowplugin项目,发送、监听、解析等功能都使用官方代码，私有代码只负责组建ICDP报文、订阅openflowplugin项目的处理结果，并进一步形成拓扑等。","categories":[{"name":"SDN","slug":"SDN","permalink":"http://example.com/categories/SDN/"}],"tags":[{"name":"拓扑发现","slug":"拓扑发现","permalink":"http://example.com/tags/%E6%8B%93%E6%89%91%E5%8F%91%E7%8E%B0/"}]},{"title":"SDN开发日志","slug":"SDN开发日志","date":"2022-10-14T13:03:38.310Z","updated":"2022-10-19T13:01:13.164Z","comments":true,"path":"2022/10/14/SDN开发日志/","link":"","permalink":"http://example.com/2022/10/14/SDN%E5%BC%80%E5%8F%91%E6%97%A5%E5%BF%97/","excerpt":"本文记录了网络小组第一次尝试开发SDN软件的过程。","text":"本文记录了网络小组第一次尝试开发SDN软件的过程。 开发环境​ 这里对开发环境做一个约定，尽量避免环境冲突，提供参考环境： win11 java version “1.8.0_202” Apache Maven 3.8.4 (9b656c72d54e5bacbed989b64718c159fe39b537) l2switch-master(sodium-sr4)：https://github.com/opendaylight/l2switch.git openflowplugin-stable&#x2F;sodium：https://github.com/opendaylight/openflowplugin.git IntelliJ IDEA Community Edition 2021.3.1 参考文献 基于Oxygen-SR4的ODL框架搭建与开发 主机发现功能​ 这里选择开发相对简单的主机发现功能约定一个简单的开发流程,说明如何使用ODL提供的机制开发功能,开发细节有待后续完善,参考了文献[1]. 获取官方l2switch源码 下载l2switch-master.zip并解压为l2switch-master文件夹 cmd进入l2switch-master文件夹,使用maven编译 mvn -T 1C clean install -DskipTests -Dskip.karaf.featureTest=true -Dmaven.test.skip=true -Dcheckstyle.skip=true -Dmaven.javadoc.skip=true -Dmaven.compile.fork=true 使用IDEA打开编译后的文件夹,这时可以看到全部的源代码,如果出现代码为非源文件的情况,首先检查IDEA-settings中的maven配置,配置正确后右键文件夹&#x3D;&gt;Mark Directory as&#x3D;&gt;Sources Root,或使用maven重载代码,可以正常在代码调用关系中跳转: 编译后的项目首先检查控制器能否正常启动，到l2switch-master\\distribution\\karaf\\target\\assembly\\bin下启动karaf.bat(linux环境下启动karaf),启动后首先查询bundle是否启动: bundle:list ​ 如果查询到许多bundle,代表控制器自动安装了这些内容,只查询到两个bundle代表服务都没启动,这时控制器的基本功能都不存在,需要手动安装features: feature:install odl-l2switch-all ​ 安装后,控制器具备l2swicth的相关功能,启动mininet也能正常连接上(必要时关闭防火墙): 如果功能不正常,可以到l2switch-master\\distribution\\karaf\\target\\assembly\\data\\log下查看karaf.log,搜索L2Switch will install a dropall flow on each switch,不存在代表控制器没有正确启动;如果在l2switch任一provider代码里添加:System.out.println(&quot;初始化packet handler&quot;);重新编译、安装features后,出现这句输出,代表控制器在我们改动后能够正常启动,可以进行下一步开发. 开发流程​ 代码开发一般是按照yang – blueprint – impl - rest进行的,下面进行说明. yang​ 在l2switch-master\\hosttracker\\implementation\\src\\main\\yang文件中新建host-tracker-notification.yang文件,用于定义截获l2switch-master\\hosttracker模块处理结果的notification: module host-tracker-notification &#123; yang-version 1; namespace \"urn:opendaylight:l2switch:host-tracker-notification\"; prefix \"host-tracker-notification\"; description \"自定义文件，用于截获host tracker模块的处理结果\"; revision 2014-05-28 &#123; description \"。\"; &#125; notification say-link&#123; leaf message&#123; type string; &#125; leaf linkType&#123; type string; &#125; leaf source&#123; type string; &#125; leaf destination&#123; type string; &#125; &#125; notification add-host&#123; leaf ip&#123; type string; &#125; leaf mac&#123; type string; &#125; leaf ncID&#123; type string; &#125; &#125; &#125; ​ 重新用maven编译项目后,会在l2switch-master\\hosttracker\\implementation\\target\\generated-sources\\mdsal-binding\\org\\opendaylight\\yang\\gen\\v1\\urn\\opendaylight\\l2switch\\host\\tracker\\notification\\rev140528下产生编译出的工具类: ​ 上述过程定义了两个notification接口,分别是addhost和saylink,addhost用于通知上线主机的信息,saylink用于通知主机和交换机间的连接关系;还定义了对应接口的builder类,可以返回两个notification接口的多态实现. blueprint​ 这里需要到blueprint中注册开发的模块初始化、需要的服务等内容，具体的操作: 在packet handler模块下新建control文件夹,新建ControlProvider.java和Hosttracker.java,前者是control的启动入口,后者是具体的功能类,ControlProvider.java中要有初始化方法和关闭方法: public class ControlProvider &#123; public void init()&#123; System.out.println(\"自定义功能\");&#125; public void close()&#123;&#125; &#125; 到packet-handler.xml中注册control:指明控制器启动时需要初始化的模块以及要执行的初始化方法. &lt;bean id=\"controlProvider\" class=\"org.opendaylight.l2switch.packethandler.control.ControlProvider\" init-method=\"init\" destroy-method=\"close\"> &lt;/bean> 重新编译、安装features后:出现新模块的初始化函数内容,代表control被自启动成功了,新加入的代码能够被正确的执行. impl 截获Host tracker模块的主机发现结果: ​ Host tracker模块具备主机发现功能,在hosttracker\\implementation\\src\\main\\java\\org\\opendaylight\\ l2switch\\hosttracker\\plugin\\internal\\HostTrackerImpl.java中可以找到相关代码.主要内容包含在三个方法中,分别是:onDataTreeChanged、onModifiedData、onDeletedData，主要改动如下,详细解析参见文章L2switch.md： public void onDataTreeChanged(Collection&lt;DataTreeModification&lt;DataObject>> changes) &#123; /**数据树的改变被转在collection集合中,遍历每一个改变并判断改变的类别, 如果是SUBTREE_MODIFIED:不处理 如果是WRITE:调用onModifiedData(identifier, rootNode);这个方法进一步调用了packetReceived方法 如果是DELETE::调用onDeletedData(identifier, rootNode);这个方法进一步调用了packetReceived方法 其它:结束*/ &#125; /**下述两个方法使用的AddHostBuilder和SayLinkBuilder是两个自定义的notification,各自包含数据*/ /**私有模块对这个方法有改动,增加的部分用region包括*/ private void onModifiedData(InstanceIdentifier&lt;?> iid, DataObjectModification&lt;?> rootNode) &#123; final DataObject dataObject = rootNode.getDataAfter(); if (dataObject instanceof Addresses) &#123; packetReceived((Addresses) dataObject, iid); //region:增加通知私有的拓扑模块添加主机 String nc_id =iid.firstIdentifierOf(NodeConnector.class).firstKeyOf(NodeConnector.class).getId().getValue(); Addresses a = (Addresses)dataObject; AddHostBuilder ab = new AddHostBuilder(); ab.setIp(a.getIp().getIpv4Address().getValue()); ab.setMac(a.getMac().getValue()); ab.setNcID(nc_id); notificationService.publish(ab.build()); //endregion &#125; else if (dataObject instanceof Node) &#123; hosts.putLocally((InstanceIdentifier&lt;Node>) iid, Host.createHost((Node) dataObject)); &#125; else if (dataObject instanceof Link) &#123; links.putLocally((InstanceIdentifier&lt;Link>) iid, (Link) dataObject); //region:增加通知私有的拓扑模块添加主机和交换机的连接 Link link=(Link)dataObject; SayLinkBuilder slb = new SayLinkBuilder(); slb.setLinkType(\"onmodified\"); slb.setMessage(link.getLinkId().getValue()); notificationService.publish(slb.build()); //endregion &#125; &#125; /**私有模块对这个方法有改动,增加的部分用region包括*/ private void onDeletedData(InstanceIdentifier&lt;?> iid, DataObjectModification&lt;?> rootNode) &#123; if (iid.getTargetType().equals(Node.class)) &#123; Node node = (Node) rootNode.getDataBefore(); InstanceIdentifier&lt;Node> iiN = (InstanceIdentifier&lt;Node>) iid; HostNode hostNode = node.augmentation(HostNode.class); if (hostNode != null) &#123; hosts.removeLocally(iiN); &#125; &#125; else if (iid.getTargetType().equals(Link.class)) &#123; // TODO performance improvement here InstanceIdentifier&lt;Link> iiL = (InstanceIdentifier&lt;Link>) iid; links.removeLocally(iiL); linkRemoved((InstanceIdentifier&lt;Link>) iid, (Link) rootNode.getDataBefore()); //region:增加通知私有的拓扑模块删除主机和交换机的连接link Link link=(Link)rootNode.getDataBefore(); SayLinkBuilder sbr = new SayLinkBuilder(); sbr.setLinkType(\"onDeleted\"); sbr.setMessage(link.getLinkId().getValue()); sbr.setSource(link.getSource().getSourceTp().getValue()); sbr.setDestination(link.getDestination().getDestTp().getValue()); notificationProviderService.publish(sbr.build()); //endregion &#125; &#125; 处理截获的主机发现结果: 这里先实现主机和交换机连接发现.详细解析参见L2switch.md:packet handler-control-listener /**1.首先实现HostTrackerNotificationListener接口并重写其中的方法*/ public class Hosttracker implements HostTrackerNotificationListener &#123; @Override public void onSayLink(SayLink notification) &#123; /*取出信息*/ String[] message=notification.getMessage().split(\"/\"); String source = notification.getSource(); String destination = notification.getDestination(); String linktype = notification.getLinkType(); System.out.println(notification.getMessage()); &#125; @Override public void onAddHost(AddHost notification) &#123; /*取出AddHost携带的信息,ncId就是openflow:1243134124:3之类的*/ String ip= notification.getIp(); String mac= notification.getMac(); String[] ncId=notification.getNcID().split(\":\");//其实ncId已经可以知道主机连接哪个交换机了 int dpid=Integer.valueOf(ncId[1]); int output_port=Integer.valueOf(ncId[2]); System.out.println(notification.getNcID());//输出看一下ncId内容 System.out.println(String.format(\"发现连接在dpid为%s的交换机的%s端口上,ip为%smac为%s的主机\"dpid,output_port,ip,mac)); &#125; &#125; /**2.在ControlProvider的初始化函数中初始化Hosttracker类*/ public class ControlProvider &#123; public final NotificationProviderService notificationProviderService; public ControlProvider(NotificationProviderService notificationProviderService) &#123; this.notificationProviderService = notificationProviderService; &#125; public void init()&#123; System.out.println(\"初始化Hosttracker\"); Hosttracker hosttracker=new Hosttracker(); notificationProviderService.registerNotificationListener(hosttracker); &#125; public void close()&#123;&#125; &#125; ​ 上述代码实现了最简单的主机发现功能,实现功能后还要按照blueprint环节的方法把编写代码对应的部分注册到blueprint中去: /**HostTrackerImpl: 在HostTrackerImpl中添加了发布notification的功能,需要在host-tracker.xml添加NotificationProviderService*/ //首先,引入NotificationProviderService 服务 &lt;reference id=\"notificationService\" interface=\"org.opendaylight.controller.sal.binding.api.NotificationProviderService\" /> //其次,在bean中添加 &lt;bean id=\"hostTrackerImpl\" class=\"org.opendaylight.l2switch.hosttracker.plugin.internal.HostTrackerImpl\" init-method=\"init\" destroy-method=\"close\"> &lt;argument ref=\"dataBroker\" /> &lt;argument ref=\"hostTrackerConfig\" /> &lt;argument ref=\"notificationService\" />//添加这一行 &lt;/bean> /**Hosttracker和ControlProvider: 这两个用到了订阅Notification的功能,也需要在packet-handler.xml添加NotificationProviderService 过程同上*/ &lt;bean id=\"controlProvider\" class=\"org.opendaylight.l2switch.packethandler.control.ControlProvider\" init-method=\"init\" destroy-method=\"close\"> &lt;argument ref=\"notificationService\" />//尤其是这一行 &lt;/bean> ​ 确定上述内容准确无误后启动karaf,安装对应features,启动mininet仿真网络连接到控制器,得到如下结果: ​ 尤其是查询bundle:list，在l2switch项目中的对应bundle应当是如下状态，全部处于active： ​ ODL中blueprint的注册至关重要,任何一个blueprint.xml的错误都会引起karaf的内部错误,查询bundle:list时会出现异常，bundle状态可能处于graceperiod(宽限期)或failure，都会导致控制器失效连接不上mininet网络，具体表现如下: rest​ 一般来说feature：odl-l2switch-all应该包括全部功能，但是在钠版本中，rest功能是分开的，需要额外安装feature:install odl-l2switch-switch-rest，安装后使用Postman的GET方法调用url，应该能得到ODL返回的结果，这部分功能暂时不涉及，留待后续处理.","categories":[{"name":"SDN","slug":"SDN","permalink":"http://example.com/categories/SDN/"}],"tags":[{"name":"开发日志","slug":"开发日志","permalink":"http://example.com/tags/%E5%BC%80%E5%8F%91%E6%97%A5%E5%BF%97/"}]},{"title":"设备上线流程梳理","slug":"设备上线流程梳理","date":"2022-09-27T08:18:21.824Z","updated":"2022-10-14T12:54:27.387Z","comments":true,"path":"2022/09/27/设备上线流程梳理/","link":"","permalink":"http://example.com/2022/09/27/%E8%AE%BE%E5%A4%87%E4%B8%8A%E7%BA%BF%E6%B5%81%E7%A8%8B%E6%A2%B3%E7%90%86/","excerpt":"​ 本文梳理了SDN系统在设备上线时的处理流程和对应代码.","text":"​ 本文梳理了SDN系统在设备上线时的处理流程和对应代码. 设备上线只有控制器和交换机第一次上线 控制器和交换机建立连接 控制器向交换机下发约定好的默认初始流表 控制器向交换机发送LLDP、ICFP等链路探测报文,并生成网络拓扑图 控制器根据网络拓扑计算路径并下发代表路径的流表,计算的路径有如下两种,其它比如某设备到外网交换机的是没有算的: 车到车,车间的路径,就是外网交换机到外面的 车内内网交换机到外网交换机的 之后有终端上线 触发hosttracker模块,获取主机的ip、mac、和交换机的连接关系,并发布成notification 终端开始对外通信,触发ARP\\IP等解码器,处理并收集结果 根据终端的通信情况计算其它部分的路径,理想情况下,上部分算过的路径不用再算,如果发现算过的有误不能到达,那么触发重新计算 代码梳理参考文献 openflow1.3规范英文版 对openflow1.3的认知 建立连接​ 这部分是OpenFlowPlugin项目提供的功能，应该不需要额外开发. 下发默认初始流表​ 这里暂定初始流表就是把无法匹配的报文上送到控制器.这里需要明确openflow13流表的细致结构,下面分别对各个流表项进行说明(不包括计量表和组表): 匹配域Match Fields:openflow13把被匹配的内容称为元组,共有40个,其中有13个元组是必备元组,其它是可选配元组.全部元组列表如下: 其中必备13元组如下表: 元组名称 编号 进入端口 0? 以太网源地址 4 以太网目标地址 3 以太网类型 5? IPv4或IPv6 10? IPv4源地址 11 IPv4目标地址 12 IPv6源地址 26 IPv6目标地址 27 TCP源端口地址 13 TCP目标端口地址 14 UDP源端口地址 15 UDP目标端口地址 16 优先级Priority:流表项的匹配优先级 计数器Counters:这个流表被匹配到多少次 指令Instructions:这条流表对报文可执行的操作 ​ 指令的类型: ​ 动作集的内容: 超时时间Timeouts:OpenFlow协议超时机制简介: 超时种类 含义 硬超时hard timeout 当该流表项的存在时间超过了预设置的硬超时，流表项就会被交换机从流表中移除。即流表项从交换机移除的绝对时间 空闲超时idle timeout 如果连续idle timeout时间内都没有匹配到这条流表,则交换机会主动将该流表项从流表中移除 cookie:由控制器选择的不透明数据值。控制器用来过滤流统计数据、流改变和流删除。 但处理数据包时不能使用 ​ 综上所述,下发的默认流表应该是所有字段通配（省略）,优先级较低,指令动作集为output到控制器端口的流表,或者是动作为drop的流表,其它三个字段视情况而定. //参看l2switch-main模块 /**组建dropall流表*/ private Flow createDropAllFlow(Short tableId, int priority) &#123; /**初始化建立流表的对象FlowBuilder,并指定把流表下到哪一个表中(table0或table1)*/ FlowBuilder dropAll = new FlowBuilder() // .setTableId(tableId) // .setFlowName(\"dropall\"); /**用哈希code作为他自己的id*/ dropAll.setId(new FlowId(Long.toString(dropAll.hashCode()))); /**建立匹配项,对于dropall流表来说这里应该是通配或者通不配,这里是匹配项为空*/ Match match = new MatchBuilder().build(); /**创建dropall动作到动作集?对应write-action?*/ Action dropAllAction = new ActionBuilder() .setOrder(0) .setAction(new DropActionCaseBuilder().build()) .build(); // 创建可选的Apply Action ApplyActions applyActions = new ApplyActionsBuilder().setAction(ImmutableList.of(dropAllAction)).build(); // 把Apply Action放到一个指令里 Instruction applyActionsInstruction = new InstructionBuilder() // .setOrder(0) .setInstruction(new ApplyActionsCaseBuilder()// .setApplyActions(applyActions) // .build()) // .build(); // 组建流表 dropAll.setMatch(match) // .setInstructions(new InstructionsBuilder() // .setInstruction(ImmutableList.of(applyActionsInstruction)) // .build()) // .setPriority(priority) // .setBufferId(OFConstants.OFP_NO_BUFFER) // .setHardTimeout(flowHardTimeout) // .setIdleTimeout(flowIdleTimeout) // .setCookie(new FlowCookie(BigInteger.valueOf(flowCookieInc.getAndIncrement()))) .setFlags(new FlowModFlags(false, false, false, false, false)); //返回一个流表对象 return dropAll.build(); &#125; /**Flowbuilder的成员对象是流表的各个表项,没看到counter?*/ public class FlowBuilder implements Builder&lt;Flow> &#123; private Long _bufferId; private String _containerName; private FlowCookie _cookie; private FlowCookie _cookieMask; private FlowModFlags _flags; private String _flowName; private Integer _hardTimeout; private FlowId _id; private Integer _idleTimeout; private Instructions _instructions; private Match _match; private Long _outGroup; private BigInteger _outPort; private Integer _priority; private Short _tableId; private Boolean _barrier; private Boolean _installHw; private Boolean _strict; private FlowKey key; &#125; /**下发流表:ODL对流表的操作分为三种: 1.addFlow:创建流表和写流表的综合方法称为添加,相当于一键创建并下发流表 addFlow&#123; writeFlowToController(nodeId, tableId, flowId, createDropAllFlow(flowTableId, flowPriority)); &#125; 2.writeFlow:把流表写到交换机 3.createFlow:创建流表本身 */ 发送协议报文​ 这里梳理如何对外发送协议报文，这里的协议报文分两种：1.openflow13消息 2.lldp或ospf协议报文。这里最好对照私有项目梳理，标准l2switch中arphandler有代码也可以参考。 解析收到的报文​ 结合decoder的梳理。 生成拓扑图​ 这里是遍历算法。 计算默认流表并下发​ 重点在如何计算流表。","categories":[{"name":"SDN","slug":"SDN","permalink":"http://example.com/categories/SDN/"}],"tags":[{"name":"初始化","slug":"初始化","permalink":"http://example.com/tags/%E5%88%9D%E5%A7%8B%E5%8C%96/"}]},{"title":"ARP流程梳理","slug":"ARP流程梳理","date":"2022-09-08T08:57:27.222Z","updated":"2022-09-29T06:45:29.762Z","comments":true,"path":"2022/09/08/ARP流程梳理/","link":"","permalink":"http://example.com/2022/09/08/ARP%E6%B5%81%E7%A8%8B%E6%A2%B3%E7%90%86/","excerpt":"​ 本文梳理了ARP的详细流程。","text":"​ 本文梳理了ARP的详细流程。 研究背景约定 连接示意图 情况说明： 左侧代表A车，右侧代表B车，每台车内交换机的dpid设计相同，暂时不考虑多外网交换机的情况 控制器没有MAC地址，内外网交换机有MAC地址，但是不关注 A、B两车各自有一台PC连接，两台PC都是第一次上线 流程梳理​ 新上线的PC会触发多个模块的功能，包括但不限于监听设备上线、ARP处理、单播等，本文认为这些模块没有明确的顺序关系，应当是并行处理的，哪个模块的条件被触发，哪个流程就可以执行。所以下面分别按照功能梳理对应的工作流程： PC1\\PC2相互ping通​ 以PC1:10.1.2.101 ping PC2:10.1.3.101为例. 对PC1命令行下发指令ping 10.1.3.101,ping指令是Icmp协议工作在IP层,会产生一个Icmp包,IP协议会把这个包封装在IP报文里面,并填上源IP:10.1.2.101和目的IP:10.1.3.101,然后把IP包交给数据链路层. 数据链路层使用去掉了无用可选项的以太网帧格式,正常的设备可以识别,在这一层需要填上目的MAC和源MAC,结构如下图,这时源MAC为PC1:11-22-33-44-55-66,目的MAC会到PC1的arp缓存里面查找,因为这是设备第一次上线,所以缓存里面没有目的IP:10.1.3.101对应的目的MAC,于是需要发送ARP请求. ARP请求也封装在以太网帧中,这时的源MAC是PC1:11-22-33-44-55-66,而目的MAC是广播:ff-ff-ff-ff-ff-ff,以太网类型是ARP(0x0806),净荷里写明想要请求MAC的IP,这个IP需要判断类别.如果请求的IP是本车内的,那么IP就正常填写,如果请求的IP是本车外的,这个IP就要填写为网关的IP:10.1.2.1.这条ARP请求会被PC1广播出去,被A车的内网交换机收到然后上送到控制器CtrlA.ARP请求示意图如下,示意图中要请求MAC的IP是10.228.90.12. CtrlA处理ARP请求的方式是创建一个ARP应答报文随意回复一个MAC地址,假设为代答MAC:11-11-11-11-11-11,应答报文也是封装在以太网帧中,源MAC是代答MAC:11-11-11-11-11-11,目的MAC是PC1:11-22-33-44-55-66,以太网类型是ARP(0x0806),净荷里写明:被请求IP对应的MAC是代答MAC:11-11-11-11-11-11.其实就是控制器替(假装自己是)PC2给PC1回了一个ARP请求(代答),让PC1尽快把报文发出来,不要跨车去找PC2的MAC,防止在链路状态不好的时候卡在这.(这里也存在控制器处理报文的过程,为了逻辑清晰在下面展开) PC1把得到的PC2:10.1.3.101对应的代答MAC:11-11-11-11-11-11写入ARP缓存,并填入Icmp的以太网报文,PC1以为的目的MAC是代答MAC:11-11-11-11-11-11,组包完成,发给A车的内网交换机. 由于是第一次上线两台车的内外网交换机都没有转发到车外的流表,因此A车内网交换机会直接上送至CtrlA,此时CtrlA面临的是一条以太网帧,具体内容是: ODL的功能不是线性的，在PC上线的瞬间会触发多个模块,包括但不限于:HostTracker发现主机、拓扑发现、流表计算下发。所以这时候应该分为两种情况,第一种:这条包含Icmp报文的以太网帧到达内网交换机的时候，拓扑发现和流表计算下发已经完成了，这是交换机按照流表进行匹配转发就可以把这个以太网帧送给B车，这条报文也就不会被上送至控制器；第二种:这条包含Icmp报文的以太网帧到达内网交换机的时候，拓扑发现和流表计算下发没有完成,交换机没有转发至B车的流表,那么这条以太网帧就会被上送给控制器,控制器就要进行处理,处理的结果应该是重新计算并下发流表,保证后续的Icmp报文可以按照第一种情况处理,也就是说,理想情况下,控制器是不应该见到这条报文的.所以,本例探讨的场景其实至少包含了三个流程:1.主机发现;2.拓扑发现和流表计算下发;3.处理报文. 为详细梳理流程,这里按照第二种情况处理. CtrlA首先接收并用以太网解码器EthernetDecoder解码报文,解码报文产生了一个EthernetPacketReceived类型的notification,它有一个packetchain成员对象,解码的结果就被放在里面,所有订阅这个notification的方法都知道收到并成功解码了一个以太网报文,解码的结果到packetchain中获取,代码片段如下: /**ODL定义了接收数据的YANG模型,并且生成了工具类,在 org.opendaylight.yang.gen.v1.urn.opendaylight.packet.service.rev130709中 有PacketReceivedBuilder.java, 底层实现水太深,把握不住 */ /**收到的报文存在PacketReceived接口的某个多态类里面*/ public interface PacketReceived extends DataObject, Augmentable&lt;PacketReceived>, PacketIn, Notification &#123; @NonNull QName QNAME = YangModuleInfoImpl.qnameOf(\"packet-received\"); default Class&lt;PacketReceived> implementedInterface() &#123; return PacketReceived.class; &#125; @Nullable Match getMatch(); &#125; /**所有类型的解码器都继承了抽象类AbstractPacketDecoder, 泛型C代表入参可以是任意类型,泛型P extends Notification */ public abstract class AbstractPacketDecoder&lt;C, P extends Notification> implements NotificationProviderService.NotificationInterestListener, AutoCloseable &#123; public void decodeAndPublish(final C consumedPacketNotification) &#123;&#125; public abstract P decode(C consumedPacketNotification); &#125; /**l2switch/packethandler/decoders/EthernetDecoder.java */ public class EthernetDecoder extends AbstractPacketDecoder&lt;PacketReceived, EthernetPacketReceived>implements PacketProcessingListener &#123; /**入参是收到的报文,对收到的报文解码并发布解码成功的消息notification 入参是用接口声明变量,是多态的写法,表示只要能实现这个接口,就都可以放这里*/ public void onPacketReceived(PacketReceived packetReceived) &#123; decodeAndPublish(packetReceived); &#125; &#125; /**初始化空的packetNotification 判断: 如果入参不为空且能够解析,就把解析结果放入packetNotification 如果packetNotification不为空,就publish发布notification*/ public void decodeAndPublish(final C consumedPacketNotification) &#123; decodeAndPublishExecutor.execute(() -> &#123; P packetNotification = null; if (consumedPacketNotification != null &amp;&amp; canDecode(consumedPacketNotification)) &#123; packetNotification = decode(consumedPacketNotification); &#125; if (packetNotification != null) &#123;notificationProviderService.publish(packetNotification); &#125; &#125;); &#125; /**因此解码的过程在抽象类decode(consumedPacketNotification) 表示对类型C的入参解码应该得到P类型的多态, decode类在EthernetDecoder.java中被重写,用来专门解码以太网帧*/ public abstract P decode(C consumedPacketNotification); /**EthernetDecoder.java中重写的decode返回一个EthernetPacketReceived类型的notification*/ @Override public EthernetPacketReceived decode(PacketReceived packetReceived)&#123; /**读收到的包的载荷到数组*/ byte[] data = packetReceived.getPayload(); /**初始化一个构造notification的对象*/ EthernetPacketReceivedBuilder builder = new EthernetPacketReceivedBuilder(); ArrayList&lt;PacketChain> packetChain = new ArrayList&lt;>(); /**开始处理报文,重点关注两个对象: ----1.解包工具,以太网报文对象,包括以太网报文的字段和方法: EthernetPacketBuilder epBuilder = new EthernetPacketBuilder(); ----2.packetchain集合,EthernetPacketReceived类型的notification中包括这个对象. 元素的类型被限制为PacketChain,处理后的以太网报文被赋给PacketChain类型,放在里面 ArrayList&lt;PacketChain> packetChain = new ArrayList&lt;>();*/ /** 处理报文过程的伪代码&#123; 保存原始rawPacket并设置载荷的Offset和Length字段 try&#123; 反序列化目标和源字段 反序列化可选字段802.1Q标头 设置802.1Q头部 反序列化EtherType或Length字段 确定有效载荷的开始和结束 反序列化CRC 设置EthernetPacket字段 设置载荷字段 &#125; &#125; */ /**解码后的以太网报文被放在ArrayList&lt;PacketChain> packetChain 中,通过setPacket方法放到 EthernetPacketReceivedBuilder的成员_packetChain中了*/ builder.setPacketChain(packetChain); return builder.build(); &#125; /**处理以太网报文产生的notification结构如下*/ public class EthernetPacketReceivedBuilder implements Builder&lt;EthernetPacketReceived> &#123; /**成员对象,packetchain里面放着以太网报文的处理结果,订阅者可以来这取结果*/ private List&lt;PacketChain> _packetChain; private byte[] _payload; &#125; /**Packetchain接口定义如下*/ public interface PacketChain extends ChildOf&lt;PacketChainGrp>,Augmentable&lt;PacketChain>&#123; public static final @NonNull QName QNAME = $YangModuleInfoImpl.qnameOf(\"packet-chain\"); @Override default Class&lt;org.opendaylight.yang.gen.v1.urn.opendaylight.packet.basepacket.rev140528.packet.chain.grp.PacketChain> implementedInterface() &#123; return org.opendaylight.yang.gen.v1.urn.opendaylight.packet.basepacket.rev140528.packet.chain.grp.PacketChain.class; &#125; @Nullable Packet getPacket(); &#125; 以太网解码后暴露出了其中的IP报文,所以需要用IPv4解码器进一步解码,解码的过程和以太网解码器非常类似: /**解码后,EthernetPacketReceived类型的notification被订阅者接收 org/opendaylight/yang/gen/v1/urn/opendaylight/packet/ethernet/rev140528/ EthernetPacketListener.java 有三个解码器实现了这个接口:ARP\\IPv4\\IPv6,Icmp应该基于IPv4*/ public interface EthernetPacketListener extends NotificationListener &#123; void onEthernetPacketReceived(EthernetPacketReceived notification); &#125; /** IPv4 Packet Decoder. */ public class Ipv4Decoder extends AbstractPacketDecoder&lt;EthernetPacketReceived, Ipv4PacketReceived> implements EthernetPacketListener &#123; @Override public void onEthernetPacketReceived(EthernetPacketReceived notification) &#123; /**decodeAndPublish的功能还是在decode方法实现*/ decodeAndPublish(notification); &#125; /**可以看见IPv4解码器的入参正好是以太网解码器的结果：EthernetPacketReceived类型的notification！ 同理，IPv4解码器返回一个 Ipv4PacketReceived类型的notification*/ @Override public Ipv4PacketReceived decode(EthernetPacketReceived ethernetPacketReceived) &#123; /**初始化 Ipv4PacketReceived类型的notification*/ Ipv4PacketReceivedBuilder ipv4ReceivedBuilder = new Ipv4PacketReceivedBuilder(); /**读出notification中PacketChain的最新数据包，是一个EthernetPacket,并在这里再创建一个元素类型是 PacketChain的集合,用来放IPv4解码结果*/ List&lt;PacketChain> packetChainList = ethernetPacketReceived.getPacketChain(); /** 处理报文过程的伪代码&#123; 读取载荷 IPv4类型的解包工具.Ipv4PacketBuilder builder = new Ipv4PacketBuilder(); try&#123; 设置version、Ihl、Dscp、Ecn等字段 解码标志——保留、DF（不分段）、MF（更多分段） “与 0xff”删除Java字节的符号 解码可选的“选项”参数 解码IPv4有效负载 &#125; 构建IPv4报文 结转原始有效载荷 &#125; */ /**返回一个Ipv4PacketReceived类型的notification,而且其中也有 一个成员_packetChain存放解码结果*/ return ipv4ReceivedBuilder.build(); &#125; IPv4解码后,应该暴露出其中的Icmp报文了,所以下一步是Icmp解码器: /**Ipv4PacketListener 订阅了Ipv4PacketReceived类型的notification, org/opendaylight/yang/gen/v1/urn/opendaylight/packet/ ipv4/rev140528/Ipv4PacketListener.java*/ public interface Ipv4PacketListener extends NotificationListener&#123; void onIpv4PacketReceived(Ipv4PacketReceived notification); &#125; /**Icmp解码器使用了Ipv4PacketListener*/ public class IcmpDecoder extends AbstractPacketDecoder&lt;Ipv4PacketReceived, IcmpPacketReceived> implements Ipv4PacketListener &#123; @Override public void onIpv4PacketReceived(Ipv4PacketReceived notification) &#123; /**decodeAndPublish继续使用decode方法*/ decodeAndPublish(notification); &#125; @Override/**返回IcmpPacketReceived类型的notification*/ public IcmpPacketReceived decode(Ipv4PacketReceived ipv4PacketReceived) &#123; /**用来创建IcmpPacketReceived类型的notification*/ IcmpPacketReceivedBuilder icmpReceivedBuilder = new IcmpPacketReceivedBuilder(); /**元素类型为PacketChain的集合,存放解码结果*/ List&lt;PacketChain> packetChainList = ipv4PacketReceived.getPacketChain(); /**Icmp类型的解包工具*/ IcmpPacketBuilder builder = new IcmpPacketBuilder(); /** 处理报文过程的伪代码&#123; try&#123; 解码ICMP类型和ICMP代码 解码校验和 解码标识符和序列号 解码净荷 &#125; 构建icmp包 结转原始有效载荷 &#125; */ /**返回一个IcmpPacketReceived类型的notification,而且其中也有 一个成员_packetChain存放解码结果*/ return icmpReceivedBuilder.build(); &#125; /**Icmp解码结果继续被订阅 org/opendaylight/yang/gen/v1/urn/opendaylight/packet/icmp/ rev140528/IcmpPacketListener.java*/ public interface IcmpPacketListener extends NotificationListener &#123; void onIcmpPacketReceived(IcmpPacketReceived notification); &#125; /**前文第4点中未展开的ARP报文解析也是一样的解码方法 ARP解码器订阅了EthernetPacketListener 返回 ArpPacketReceived类型的notification，继续被自己的订阅者监听 */ public class ArpDecoder extends AbstractPacketDecoder&lt;EthernetPacketReceived, ArpPacketReceived> implements EthernetPacketListener &#123; @Override public void onEthernetPacketReceived(EthernetPacketReceived notification) &#123; decodeAndPublish(notification); @Override public ArpPacketReceived decode(EthernetPacketReceived ethernetPacketReceived) &#123; ArpPacketReceivedBuilder arpReceivedBuilder = new ArpPacketReceivedBuilder(); List&lt;PacketChain> packetChainList = ethernetPacketReceived.getPacketChain(); ArpPacketBuilder builder = new ArpPacketBuilder(); /**解析过程，不赘述*/ return arpReceivedBuilder.build(); &#125; &#125; /**ARP报文的后续处理流程暂不展开*/ 本例的目的是让PC1和PC2能ping通，实际上是不关心Icmp报文的具体内容的，最主要的是提取报文中的目的MAC、源MAC、目的IP、源IP，因此IPv4解码结果还有另外两个订阅者：AddressObserverUsingIpv4和SimpleAddressObserver,前者用于解析地址:根据IPv4解码器的结果把mac地址、ip地址根据索引存到数据树中,后者用于追踪主机:进一步处理ARP解码器和IPv4解码器的结果. /**AddressObserverUsingIpv4: AddressObserver侦听IPv4数据包以查找地址(mac、ip),并为每个节点连接器存储这些地址观察。 在学习地址之后，这些数据包返回到网络.*/ public class AddressObserverUsingIpv4 implements Ipv4PacketListener &#123; @Override/**处理IPv4解码结果*/ public void onIpv4PacketReceived(Ipv4PacketReceived packetReceived) &#123; /** 处理报文过程: 验证packetReceived是否为空 初始化相关报文: RawPacketFields rawPacket = null; EthernetPacket ethernetPacket = null; Ipv4Packet ipv4Packet = null; 遍历packetchain中的每个元素,判断是什么类别,并把元素放到对应类型的报文中 判断存放的报文是否为空 再判断是否是忽略的IP,否则进一步处理，也就是调用addressObservationWriter.addAddress方法*/ if (!IPV4_IP_TO_IGNORE.equals(ipv4Packet.getSourceIpv4().getValue())) &#123; addressObservationWriter.addAddress(ethernetPacket.getSourceMac(), IpAddressBuilder.getDefaultInstance(ipv4Packet.getSourceIpv4().getValue()), rawPacket.getIngress()); &#125; &#125; &#125; /**AddressObservationWriter管理每个node-connector地址观察（mac、ip）的MD-SAL数据树。 只有一个成员方法,就是addAddress */ public class AddressObservationWriter &#123; /**将地址添加到MD-SAL数据树中,入参:Mac地址、IP地址、节点连接参考，里面存着前面MAC和IP地址 的索引，也就是说：addAddress方法，根据索引把对应的mac、ip地址存到数据树中，再下面就是底层实现，暂不深究*/ public void addAddress(MacAddress macAddress, IpAddress ipAddress, NodeConnectorRef nodeConnectorRef) &#123;&#125; &#125; /**NodeConnectorRef理解为：描述的是节点连接的那根线，*/ public class NodeConnectorRef implements TypeObject, Serializable &#123; /**最关键的就是 _value 成员,它是InstanceIdentifier类型的泛型类,泛型是&lt;T extends DataObject> 包括但不限于动作、桶等，是SDN中很多内容的唯一索引，这里可以看耿老师的书*/ private final InstanceIdentifier&lt;?> _value; public InstanceIdentifier&lt;?> getValue() &#123; return this._value;&#125; &#125; /**SimpleAddressObserver:基于l2switch地址观测器的简单地址观测器,位于hosttracker模块*/ public class SimpleAddressObserver implements ArpPacketListener, Ipv4PacketListener, Ipv6PacketListener &#123; /**成员变量*/ private static final String IPV4_IP_TO_IGNORE = \"0.0.0.0\"; private static final String IPV6_IP_TO_IGNORE = \"0:0:0:0:0:0:0:0\"; private final HostTrackerImpl hostTrackerImpl;//主机追踪主要功能 private final NotificationService notificationService; /**构造器*/ /**成员方法*/ registerAsNotificationListener(); /**监听了ARP\\IPv4\\IPv6解码器返回的notification,获取结果后进一步处理 最终调用了hostTrackerImpl.packetReceived()方法*/ onArpPacketReceived(); onIpv4PacketReceived(); onIpv6PacketReceived(); /**上述三个处理过程调用的方法*/ createAddresses(); &#125; 经过解码,控制器已经知道了这个报文的源、目的mac和ip等信息，下一步应该触发重新计算下发流表功能了。 如何生成网络报文ARP为例如何发出网络报文arp回应packet_in\\outicfplldp","categories":[{"name":"SDN","slug":"SDN","permalink":"http://example.com/categories/SDN/"}],"tags":[{"name":"ARP","slug":"ARP","permalink":"http://example.com/tags/ARP/"}]},{"title":"OpenDayLight提高篇","slug":"OpenDayLight提高篇","date":"2022-09-07T02:39:57.742Z","updated":"2022-10-19T09:18:14.169Z","comments":true,"path":"2022/09/07/OpenDayLight提高篇/","link":"","permalink":"http://example.com/2022/09/07/OpenDayLight%E6%8F%90%E9%AB%98%E7%AF%87/","excerpt":"​ 本文记录了OpenDayLight提高篇：ODL集群与分布式的学习过程。","text":"​ 本文记录了OpenDayLight提高篇：ODL集群与分布式的学习过程。 ODL集群与分布式参考文献 OpenDaylight应用开发–提高篇 ODL集群到底怎样搭建 ODL集群搭建实验 ODL分布式集群底层实现分析 了解ODL控制器集群 OpenDaylight Lithium-SR2 Cluster集群搭建 搭建操作基本概念 集群：多个节点执行相同的任务，这些节点就是集群 分布式：将一个任务分布到不同的节点完成，这些节点协同工作、相互依赖，就构成了分布式 硬件要素：节点(逻辑实体,进程\\程序之类)和网络 软件要素: 要素 作用 分片 分布式的数据不可能在一个节点上,如何平衡多个节点的数据分发问题 一致性 相关连的数据之间的逻辑关系是否正确和完整，数据本身是否正确 可用性 每一个操作都能在一定时间内返回结果(备份\\保护\\可靠) 分区容忍性 分布式中不可能所有节点都能时时连通,必须考虑局部失联的情况 CAP原则 一致性(Consistency)、可用性(Availability)、分区容忍性(Partition Tolerance)三个要素互相牵制，不可能同时满足，必须折衷 ODL分布式集群的初衷与动机:Scalability(扩展性)、Performance(性能)、High Availablity(高可用) AKKa Akka框架基本要点介绍 AKKa:ODL构建集群的基础,一种高并发、分布式、弹性的、基于消息驱动的程序框架\\工具集,基于JVM运行,可以用Java或Scala开发. Actor模型:提出于1973年的分布式并发编程模型，定义了系统各个组件之间如何动作或交互的通用规则，actor指的是一个最基本的单元，actor之间不共享状态,只能通过松耦合的消息交互并执行后续动作,简化了分布式锁的操作. AKKa组件: Cluster组件:Akka Cluster（一）、Akka Cluster（二）配置说明课时一:43:00 Persistence(持久性)组件:Journal:保存全部操作,下次恢复时直接回放即可;Snapshot:只保存当前的状态.配置说明课时一:48:00 Remoting组件:跨节点通信 Datastore 和 rpc能够跨节点使用,notification不行,前两者都使用了AKKa, Gossip协议简介 Leveldb 基本介绍和使用指南 搭建ODL集群 手动配置 脚本配置 Routed RPC​ routed rpc的使用和原理跟分布式集群工作有关。 DistributedDataStore的分片分片策略 分片的定义：数据分片(Sharding)就是用来确定数据在多台存储设备上分布的技术,按照一定规则,将数据划分为相互独立、正交的数据子集,并将这些子集分布到不同的节点上. 基于yang-model的分片:氦版本的粗粒度分片 基于的yang的路径前缀分片:碳版本细粒度分片,一种颜色代表一个分片,默认使用Clustered Data Store. 分片策略:模块名字、前缀等策略 分片配置和编程接口 ModuleShardingStrategy: 通过读取配置文件modules.conf和module-shards.conf; PrefixShardingStrategy:通过编程定义: public interface DistributedShardFactory&#123; CompletionStage&lt;DistributedShardRegistration>createDistributedShard(DOMDataTreeIdentifier prefix,Collection&lt;MemberName> replicaMembers) throw DOMDataTreeShardingConflictException; &#125; /**blueprint*/ &lt;reference id=\"distributedShardFactory\" interface=\"org.opendaylight.controller.cluster.sharding.DistributedShardFactory\"> 演示实例​ 以controller项目中samples模块为例进行说明.使用工具JConsole.exe查看创建的分片. 分片的问题 复杂性提高 可靠性降低 DataStore Consisitency 数据一致性数据分片后的问题和约束条件 维持多个数据分片上操作的原子性. 同一个数据分片的多个副本之间的数据一致性. FLP不可能性:在异步通信场景下,即使只有一个进程失败,也没有任何算法能保证非失败进程达到一致性. CAP原则:一致性(Consistency)、可用性(Availability)、分区容忍性(Partition Tolerance)三个要素互相牵制，不可能同时满足，必须折衷 二阶段、三阶段提交​ 在计算机网络及数据库的范畴下,使得一个分布式系统内的所有节点能够执行事务的提交的一种分布式算法,三阶段提交是为解决两阶段提交协议的缺点而设计的 参考文献: 分布式事务:三阶段提交(3PC)协议 三阶段提交（3PC） Raft算法​ ODL使用Raft算法维持分布式节点的一致性.在介绍Raft之前先了解Paxos算法,它是目前最经典的一致性算法. Paxos算法: Raft算法:简化了Paxos算法的工程实践. DataStore配置管理 JConsole.exe jolokia(ODL提供的) ODL提供了一些budle用来管理分片等:cluster-main EntityOwnershipService实体所有权服务问题背景以及解决思路 早期版本中,openflowplugin在多控制器集群中不支持集群实例的主备,多个控制器上的openflowplugin都有可能操作底层的SDN设备,会导致流表混乱的问题","categories":[{"name":"SDN","slug":"SDN","permalink":"http://example.com/categories/SDN/"}],"tags":[{"name":"ODL","slug":"ODL","permalink":"http://example.com/tags/ODL/"}]},{"title":"OpenDayLight基础篇","slug":"OpenDayLight基础篇","date":"2022-09-07T02:39:57.737Z","updated":"2022-10-19T08:40:01.345Z","comments":true,"path":"2022/09/07/OpenDayLight基础篇/","link":"","permalink":"http://example.com/2022/09/07/OpenDayLight%E5%9F%BA%E7%A1%80%E7%AF%87/","excerpt":"​ 本文记录了OpenDayLight基础篇的学习过程。","text":"​ 本文记录了OpenDayLight基础篇的学习过程。 工程名字按照建立顺序命名，规则为Project+名称+序号，使用大驼峰模式。例如：ProjectTest1； 参考文献 OpenDaylight应用开发–基础篇 [ODL技术内幕：架构设计与实现原理](D:\\a研究生资料\\研二\\OpenDayLight\\ODL技术内幕：架构设计与实现原理 (耿兴元) (z-lib.org).epub) Maven仓库搜索(一) Maven仓库搜索(二) 官方Github 基于Oxygen-SR4的ODL框架搭建与开发 官方不同版本的对应关系(不全) 来源网络——ODL浅析 2016年SDNLAB十大热门原创文章 软件环境 java version “1.8.0_202” Apache Maven 3.8.4 (9b656c72d54e5bacbed989b64718c159fe39b537) 其它：Postman、VMware、Intellij Idea、cmd、mininet、ovs… 获取OpenDayLight项目源码 下载openflowplugin.zip，在父pom文件下安装到本地,需要联网,非常依赖版本关系,目前已知的是钠版本的openflowplugin可以顺利编译通过l2switch的master分支可以编过 mvn -T 1C clean install -DskipTests -Dskip.karaf.featureTest=true -Dmaven.test.skip=true -Dcheckstyle.skip=true -Dmaven.javadoc.skip=true -Dmaven.compile.fork=true mvn clean install -DskipTests -Dmaven.javadoc.skip=true -Dcheckstyle.skip=true -e 新建OpenDayLight项目骨架参考文献 ODL官方开发指导文档 标准流程​ 这里总结了建立ODL项目骨架的标准流程,主要是两条构建命令(1.生成骨架;2.安装到本地),还深入研究了一下获取构建原型的网址和原理. 向标准maven的settings.xml添加odlparent settings.xml内容,添加后的内容为settings-标准版添加odlparentsettings内容.xml; 要为OpenDaylight版本找到正确的项目原型版本Archetype-Version，请在https://nexus.opendaylight.org中keyword搜索opendaylight-startup-archetype,得到两个结果: ​ ODL官方认为项目原型应该使用archetypes而不是controller,但是controller仍然在更新,并且最近更新时间在archetypes之后,而且我认为项目原型不应该和版本有明确的强关联,关联关系应该由pom文件手动配置,controller中包的readme内容如下, The org.opendaylight.controller:opendaylight-startup-archetype has been replaced by the org.opendaylight.archetypes:opendaylight-startup-archetype (note how the archetypeGroupId does not contain \"controller\" anymore, but ends with \".archetypes\"),and has a different version now. ​ archetypes下的版本号如下图: 在E:\\SDN\\OpenDayLight\\ProjectTest1进入cmd，生成项目骨架，建议使用第一种，第二种在运行karaf时会产生环境错误: //按网络教程使用controller原型 mvn archetype:generate -DarchetypeGroupId=org.opendaylight.controller -DarchetypeArtifactId=opendaylight-startup-archetype -DarchetypeRepository=http://nexus.opendaylight.org/content/repositories/public/ -DarchetypeCatalog=remote -DarchetypeVersion=1.5.1 //按官方说明,使用archetypes原型,且不使用snapshot版本 mvn archetype:generate -DarchetypeGroupId=org.opendaylight.archetypes -DarchetypeArtifactId=opendaylight-startup-archetype -DarchetypeRepository=https://nexus.opendaylight.org/content/repositories/opendaylight.release/-DarchetypeCatalog=remote -DarchetypeVersion=1.2.2 填写项目信息，填写不当可能导致莫名错误： copyright：版权方，填公司名称，不能数字开头，s401； copyrightYear、version：默认； groupId：团队名称，建议小驼峰模式； artifactId：项目名，建议小驼峰模式； package、classPrefix：包名、类前缀，建议默认，尤其是classPrefix。 项目文件夹名字为artifactId，进入…\\artifactId运行cmd，安装项目到本地: mvn clean install -DskipTests -Dmaven.javadoc.skip=true -Dcheckstyle.skip=true -e 第一个项目：Helloworld参考文献 枫零NET的教程; u_hcy2000的博客 三、OpenDaylight应用基础开发（ODL的Hello World）; 耿兴元老师OpenDaylight应用开发–基础篇; 建立项目ProjectHelloworld1​ 从无到有生成一个标准的ODL项目，体验一个简单ODL功能的实现，熟悉ODL的框架，对ODL有个基本的认识。 按照标准构建流程生成项目骨架、填写项目信息并安装到本地 功能实现 定义YANG文件: 在&#x2F;api&#x2F;src&#x2F;main&#x2F;yang下helloworld.yang文件module{}中添加: rpc hello-world &#123; input &#123; leaf name &#123; type string; &#125; &#125; output &#123; leaf greeting &#123; type string; &#125; &#125; &#125; 重新安装项目到本地,上述yang模型会在api&#x2F;target&#x2F;generated-sources&#x2F;mdsal-binding&#x2F;org.opendaylight.yang. gen.v1.utn.opendaylight.params.xml.ns.yang.&lt;项目名&gt;.rev&lt;数字&gt;下生成数个类和接口. 进入impl&#x2F;src&#x2F;main&#x2F;java&#x2F;networkGroup&#x2F;impl&#x2F;HelloworldProvider.java下实现代码; 进入impl&#x2F;src&#x2F;main&#x2F;resources&#x2F;org&#x2F;opendaylight&#x2F;blueprint&#x2F;impl-blueprint.xml,在&lt;blueprint&gt;&lt;/blueprint&gt;中添加&lt;odl:rpc-implementation ref=&quot;provider&quot;/&gt;; 重新安装项目,运行E:\\SDN\\OpenDayLight\\ProjectHelloworld1\\helloworld\\karaf\\target\\assembly\\bin\\karaf.bat; 使用Postman，POST方式调用 http://localhost:8181/restconf/operations/helloworld:hello-world； YANG模型和自动生成的工具类、工具接口的对应关系: 是哪些代码实现了读取数据和发送数据的: RPC：Remote Procedure Call基本概念 RPC有两类：Global RPC和Routed RPC 类别 区别 Global RPC 一个节点上只有一个RPC实例会被调用，注册多个实例时第一个注册的生效 Routed RPC 通过不同的RoutedId可以调用不同的RPC实例 如何理解ODL中的RPC：异步的响应模式，单播关系 编程实战LLDP2Controller​ 通过RPC调用openflowplugin项目提供的下发流表功能实现上送LLDP报文到控制器的操作，该功能涉及配置POM文件、获取RPC、注册RPC、配合mininet验证等内容,在Helloworld项目基础上实现.通过调用别的项目定义好的rpc，就不需要自己定义yang文件 新建项目ProjectCustom1​ 经过测试,ODL官网推荐的opendaylight-startup-archetype下的项目原型生成后编译运行会报错,因此这里使用网络版本，版本号使用1.5.1 mvn archetype:generate -DarchetypeGroupId=org.opendaylight.controller -DarchetypeArtifactId=opendaylight-startup-archetype -DarchetypeRepository=http://nexus.opendaylight.org/content/repositories/public/ -DarchetypeCatalog=remote -DarchetypeVersion=1.5.1 mvn clean install -DskipTests -Dmaven.javadoc.skip=true -Dcheckstyle.skip=true LLDP2Controller实现​ 这个功能需要mininet和karaf的配合,因此需要实现一下两点,同时保证添加的features和代码的依赖不冲突: 添加features-openflowplugin,让karaf具备连接交换机的功能,版本0.6.1 &lt;dependency> &lt;groupId>org.opendaylight.openflowplugin&lt;/groupId> &lt;artifactId>features-openflowplugin&lt;/artifactId> &lt;version>0.6.1&lt;/version> &lt;type>xml&lt;/type> &lt;classifier>features&lt;/classifier> &lt;/dependency> &#x2F;**编译后在karaf安装一下,经测试可以连接到mininet*&#x2F; karaf@root()&gt; feature:install features-openflowplugin karaf@root()&gt; feature:install features-custom1 &#x2F;**创建mininet网络*&#x2F; mn --controller&#x3D;remote,ip&#x3D;192.168.0.16,port&#x3D;6633 --topo&#x3D;tree,2 实现LLDP2Controller功能: ​ 在networkGroup.impl下新建LLDPToControllerFlowWriter.java,添加功能依赖: &lt;!--依赖的内容都来自openflowplugin,在impl/pom.xml下 &lt;dependencyManagement>&lt;/dependencyManagement>指定依赖的版本:0.6.1--> &lt;dependency> &lt;groupId>org.opendaylight.openflowplugin&lt;/groupId> &lt;artifactId>openflowplugin-artifacts&lt;/artifactId> &lt;version>0.6.1&lt;/version> &lt;type>pom&lt;/type> &lt;scope>import&lt;/scope> &lt;/dependency> &lt;!--在impl/pom.xml&lt;dependencies>&lt;/dependencies>说明依赖的具体模块--> &lt;dependency> &lt;groupId>org.opendaylight.openflowplugin&lt;/groupId> &lt;artifactId>openflowplugin-api&lt;/artifactId> &lt;/dependency> &lt;dependency> &lt;groupId>org.opendaylight.openflowplugin&lt;/groupId> &lt;artifactId>openflowplugin-common&lt;/artifactId> &lt;/dependency> &lt;dependency> &lt;groupId>org.opendaylight.controller.model&lt;/groupId> &lt;artifactId>model-inventory&lt;/artifactId> &lt;/dependency> &lt;dependency> &lt;groupId>org.opendaylight.openflowplugin.model&lt;/groupId> &lt;artifactId>model-flow-service&lt;/artifactId> &lt;/dependency> ​ 添加上述依赖后Reload all maven projects,实现LLDP2Controller代码就不会报bug了. 在impl&#x2F;resources&#x2F;org&#x2F;opendaylight&#x2F;blueprint&#x2F;impl-blueprint.xml中声明调用的Rpc服务: &lt;odl:rpc-service id=\"flowService\" interface=\"org.opendaylight.yang.gen.v1.urn.opendaylight.flow.service.rev130819.SalFlowService\"/> ​ 把LLDPToControllerFlowWriter.java注册到blueprint: &lt;bean id=\"LLDPToControllerFlowWriter\" class=\"networkGroup.impl.LLDPToControllerFlowWriter\" init-method=\"start\" destroy-method=\"close\"> &lt;argument ref=\"dataBroker\" /> &lt;argument ref=\"flowService\" /> &lt;/bean> ​ 上述步骤添加过LLDPToController依赖后编译,又出现了控制器连不上mininet的情况,再删掉添加的依赖,又能够连接,可以确定出现了冲突. 项目冲突分析 查看Karaf服务列表service:list,发现没有Salflowservice服务,但是在工程中SalFlowService接口可以跳转,说明虽然找到了依赖的包,但是这个服务没有被成功加载. 查看win11的端口6633netstat -an | findstr 6633,发现不在监听6633端口,导致mininet连接不上 查看karaf的报错日志lde,发现存在 Error obtaining interface class org.opendaylight.yang.gen.v1.urn.opendaylight.flow.service.rev130819.SalFlowService 错误,说明找不到这个接口,导致服务加载不上 把依赖的项目版本由0.6.1改为0.8.1,编译时甚至出现语法error,推测是版本的问题 解决项目冲突 待解决. Ping Hosts​ 新建项目ProjectPingHosts1实现Ping Hosts功能. 编写yang文件,该文件定义了实现Ping Hosts功能的输入与输出格式和内容: module ping &#123; namespace \"urn:opendaylight:ping\"; prefix ping; import ietf-inet-types &#123; prefix \"inet\"; revision-date 2013-07-15; &#125; revision \"2017-08-26\" &#123; description \"TCP ping module\"; &#125; rpc ping-hosts &#123; description \"Send TCP ECHO request\"; input &#123; leaf async &#123; type boolean; &#125; list destination-all &#123; leaf destination &#123; type inet:ipv4-address; &#125; &#125; &#125; output &#123; list echo-result-all &#123; leaf destination &#123; type inet:ipv4-address; &#125; leaf echo-result &#123; type enumeration &#123; enum \"reachable\" &#123; value 0; description \"Received reply\"; &#125; enum \"unreachable\" &#123; value 1; description \"No reply during timeout\"; &#125; enum \"error\" &#123; value 2; description \"Error happened\"; &#125; &#125; description \"Result types\"; &#125; &#125; &#125; &#125; &#125; 由于导入了其它module,需要引入对应的依赖,否者会报bug,然后编译安装到本地: //bug内容: Cannot resolve QNameModule for 'inet' [at D:\\...] //解决措施:在...\\pingHosts\\api\\pom.xml中&lt;dependencies> &lt;/dependencies>添加依赖 &lt;dependency> &lt;groupId>org.opendaylight.mdsal.model&lt;/groupId> &lt;artifactId>ietf-inet-types-2013-07-15&lt;/artifactId> &lt;version>1.2.2-Carbon&lt;/version> &lt;/dependency> 实现功能代码,见项目文件 向impl-blueprint.xml中进行注册: &lt;odl:rpc-implementation ref=\"provider\" /> Notification基础概念 参考文献 ODL中Yang模型的通知(Notification)简介及报文接收方法 如何理解ODL中的Notification：提供者把消息发送给所有订阅该消息的消费者，组播关系 Notification的配置：Notification使用了”Disruptor”队列,所以初始化要配置队列,ODL没有这个配置文件,需要自己创建 //depth:队列的大小,必须设置为2^n,一般是业务量的二倍 //spin time:死循环时间 //park time:等待时间 &lt;cm:property-placeholder persistent-id=\"org.opendaylight.mdsal.dom.notification\" update-strategy=\"none\"> &lt;cm:default-properties> &lt;cm:property name=\"notification-queue-depth\" value=\"65536\"/> &lt;cm:property name=\"notification-queue-spin\" value=\"0\"/> &lt;cm:property name=\"notification-queue-park\" value=\"0\"/> &lt;/cm:default-properties> &lt;/cm:property-placeholder> 如何发布一条Notification //订阅服务接口 //xml中的封闭元素? &lt;reference id=\"notificationService\" interface=\"org.opendaylight.controller.md.sal.binding.api.NotificationPublishService\"/> /*在需要使用的bean中引用该服务,再通过进一步编程实现发布Notification的功能*/ &lt;argument ref=\"notificationProviderService\" /> //调用方法发布Notification //把消息放到队列中,如果队列满了会抛异常 void putNotification(Notification notification) ； //等待队列有空闲再把消息放到队列 ListenableFuture&lt;?> offerNotification(Notification notification); //在超时时间内,等待队列有空闲再把消息放到队列,如果时间到了还没有空闲就抛出异常 ListenableFuture&lt;?> offerNotification(Notification notification, int timeout, TimeUnit unit)； //这样是发布Notification嘛:registerNotificationListener this.listenerRegistrations.add(notificationService.registerNotificationListener(addressObserverUsingArp)); 如何订阅一条Notification ​ 先在YANG文件中定义一个Notification,然后编译通过YANGTools生成Listener接口,实现接口方法,然后在blueprint中注册.例如: //定义YANG notification toasterOutOfBread &#123;&#125; notification toasterRestocked &#123; leaf amountOfBread &#123; type uint32; &#125; &#125; //生成接口 public interface ToasterListener extends NotificationListener &#123; void onToasterOutOfBread(ToasterOutOfBread notification); void onToasterRestocked(ToasterRestocked notification); &#125; //注册:先用bean实例化方法类,再用 odl:notification-listener 注册类 &lt;bean id=\"kitchenService\" class=\"org.opendaylight.controller.sample.kitchen.impl.KitchenServiceImpl\" init-method=\"register\" destroy-method=\"unregister\"> &lt;argument ref=\"toasterService\"/> &lt;/bean> &lt;odl:notification-listener ref=\"kitchenService\"/> 编程实践​ 新建项目ProjectNotification1,尝试使用archetypes原型(失败). 注册监听OpenFlow的PacketIn消息，收到消息后打印消息类型 /*先实现一个可以处理PacketIn消息的类*/ public class PacketInHandler implements PacketProcessingListener &#123; private static final Logger LOG = LoggerFactory.getLogger(PacketInHandler.class); @Override public void onPacketReceived(PacketReceived notification) &#123; LOG.info(\"收到PacketIn消息\"+notification.toString()); &#125; &#125; /*用bean元素描述这个类,还都是封闭元素*/ &lt;bean id=\"packetInHandler\" class=\"networkGroup.impl.PacketInHandler\"/> /*监听注册*/ &lt;odl:notification-listener ref=\"packetInHandler\"/> 用Yang定义一个notification Java代码实现Yang notification生成的Listener接口 写代码构造notification消息并发布notification Datastore基本概念 Datastore：ODL的内存数据库，其存储的数据结构是由YANG定义的树状的结构，包括基于事务的访问与操作、支持数据变更通知、支持事务链等 Data Tree：所用和状态有关的数据都被建模和表示为Data Tree,Data Tree可以定位到任何元素或子树，Data Tree有两种：Operational Data Tree和Configuration Data Tree(数据树和配置树) Operational Data Tree：报告整个系统的状态，是基于MD-SAL发布的 Configuration Data Tree：由用户填充的系统的预期状态 Instance Identifier：树上某个节点的唯一标识 Transaction(事务)：MD-SAL数据代理(DataBroker)提供的基于事务的对Data Tree的访问 访问Datastore DataBroker：理解为数据代理，是OSGi的一个服务，通过Data Broker可以读写数据库 &lt;reference id=\"dataBroker\" interface=\"org.opendaylight.controller.md.sal.binding.api.DataBroker\" odl:type=\"default\" /> DataBroker服务接口: public interface DataBroker extends DataTreeChangeService &#123; /*创建读写等事务的方法:只读\\读写\\只写*/ ReadOnlyTransaction newReadOnlyTransaction(); ReadWriteTransaction newReadWriteTransaction(); WriteTransaction newWriteOnlyTransaction(); /*创建事务链的方法*/ BindingTransactionChain createTransactionChain(TransactionChainListener listener); &#125; /*监听数据变更,注册DataTreeListener方法*/ public interface DataTreeChangeService &#123; ListenerRegistration&lt;L> registerDataTreeChangeListener(@Nonnull DataTreeIdentifier&lt;T> treeId, @Nonnull L listener); &#125; public interface ReadOnlyTransaction &#123; /*Optional&lt;T>类型帮助判断是否读到数据了*/ CheckedFuture&lt;Optional&lt;T>> read(LogicalDatastoreType store, InstanceIdentifier&lt;T> path); @Override void close(); &#125; public interface WriteTransaction &#123; &lt;T extends DataObject> void put(LogicalDatastoreType store, InstanceIdentifier&lt;T> path, T data); &lt;T extends DataObject> void merge(LogicalDatastoreType store, InstanceIdentifier&lt;T> path, T data); &lt;T extends DataObject> void merge(LogicalDatastoreType store, InstanceIdentifier&lt;T> path, T data,boolean createMissingParents); @Override void delete(LogicalDatastoreType store, InstanceIdentifier&lt;?> path); boolean cancel(); CheckedFuture&lt;Void,TransactionCommitFailedException> submit(); &#125; DataChangeEvent(数据变更通知): /*注册监听器,说明要监听哪一个节点*/ ListenerRegistration&lt;L> registerDataTreeChangeListener(@Nonnull DataTreeIdentifier&lt;T> treeId, @Nonnull L listener); /*处理变更通知*/ public interface org.opendaylight.mdsal.binding.api. DataTreeChangeListener &#123; void onDataTreeChanged(@Nonnull Collection&lt;DataTreeModification&lt;T>> changes); &#125; //DataChangeListener已经被社区废弃 TransactionChain(事务链):实际操作中,写数据后立刻读取刚写入的数据不一定保证能得到正确的结果,因为有些是异步的操作,因此,事务链的初衷就是保证事务链里的事务按序提交,让每个事务可以看到前面的事务的操作结果.事务链不能保证事务链里的一连串事务的原子性,但是事务会按照提交的顺序被尽快提交.事务可以理解为一些列动作的封装，保正原子性 //DataBroker： @Override /*创建事务链*/ BindingTransactionChain createTransactionChain(TransactionChainListener listener); public interface BindingTransactionChain &#123; @Override /*创建读事务方法*/ ReadTransaction newReadOnlyTransaction(); @Override /*创建写事务方法*/ WriteTransaction newWriteOnlyTransaction(); &#125; 向ODL中添加Features添加Features流程 添加前查询相关features: 添加位置： 添加格式： &lt;dependency> &lt;groupId>org.opendaylight.openflowplugin&lt;/groupId> &lt;artifactId>features-openflowplugin&lt;/artifactId> &lt;version>0.6.1&lt;/version> &lt;type>xml&lt;/type> &lt;classifier>features&lt;/classifier> &lt;/dependency> 添加、编译后: 如何理解项目的feature模块结构 解析——来源网络 如何知道应该引用哪些features 用mvn dependency:tree可以明确梳理项目模块依赖关系，尤其是查看版本 控制器连接交换机的功能需要features-openflowplugin： &lt;dependency> &lt;groupId>org.opendaylight.openflowplugin&lt;/groupId> &lt;artifactId>features-openflowplugin&lt;/artifactId> &lt;version>0.6.1&lt;/version> &lt;type>xml&lt;/type> &lt;classifier>features&lt;/classifier> &lt;/dependency> features-l2switch： &lt;dependency> &lt;groupId>org.opendaylight.l2switch&lt;/groupId> &lt;artifactId>features-l2switch&lt;/artifactId> &lt;version>0.6.0&lt;/version> &lt;scope>runtime&lt;/scope> &lt;type>xml&lt;/type> &lt;classifier>features&lt;/classifier> &lt;/dependency> RESTCONF协议在sal-rest-connector组件实现,使用odl-restconf-all加载,但是不含数据结构,例如使用OpenFlow结构就要加载odl-flow-model和odl-flow-services. YANGMAN： /**helloworld项目中在 features/odl-artifactid-rest/pom.xml中添加*/ &lt;dependency> &lt;groupId>org.opendaylight.dluxapps&lt;/groupId> &lt;artifactId>odl-dluxapps-yangman&lt;/artifactId> &lt;version>0.7.1&lt;/version> &lt;type>xml&lt;/type> &lt;classifier>features&lt;/classifier> &lt;/dependency> 简单综合案例:自定义项目​ 在学习RPC和Notification的过程中,报出的一些列问题尤其是mininet连接不上和缺少对应features两个问题,让编程实践环节的内容仅仅实现了HelloWorld，下发流表、监听PackerIn等内容均无法实现，在向现有项目增加功能时，还出现了版本冲突、包依赖冲突导致Karaf异常的情况，因此，本文在这里定义一个新的自定义项目，综合完成RPC和Notification的编程实践. 简单综合案例:学生管理参考文献 基于Oxygen-SR4的ODL框架搭建与开发 ODL官方Controller文档 ODL官方开发指导文档 boron源码中的sample例子 osgi-blueprint 技术要点 远程调用:rpc 数据库:datastore 数据监听:datachangelistener 通知与订阅:notification ODL:Tipsslf4j（Simple Logging Facade for Java） 不是具体的日志系统，而是为某个日志系统提供服务，它不影响最终用户选择哪种日志系统，方便在不懂代码的情况下切换日志框架 核心是一些API和LoggerFactory类，它本身也带有一个简单的日志框架 简单会用即可 序列化反序列化 序列化： 将数据结构或对象转换成二进制字节流的过程 反序列化：将在序列化过程中所生成的二进制字节流的过程转换成数据结构或者对象的过程 需要通过网络传输对象、存储到文件、存储到数据库的时候需要序列化&#x2F;反序列化 JDK 自带的序列化，只需实现 java.io.Serializable接口即可(性能较差,但是ODL部分类使用了该接口) hashCode() hashCode就是对象的散列码，是根据对象的某些信息推导出的一个整数值，默认情况下表示是对象的存储地址。通过散列码，可以提高检索的效率，主要用于在散列存储结构中快速确定对象的存储地址 和equals()、toString()可以看做Java类的标配 字段（Field） java反射– Field 用法实践 简单理解就是：我们可用通过Field类对类或对象的field进行动态操作 **field在ODL\\Java中的作用是什么?**SDN更换报文字段的功能是否是基于Field实现的？ FlowBuilder org.opendaylight.yang.gen.v1.urn.opendaylight.flow.inventory.rev130819.tables.table下的类,功能是构建流表Flow openflow1.3流表项构成: public class FlowBuilder implements Builder&lt;Flow> &#123; private Long _bufferId; private String _containerName; //由控制器选择的不透明数据值。控制器用来过滤流统计数据、流改变和流删除,但处理数据包时不能使用 private FlowCookie _cookie; private FlowCookie _cookieMask;//?? private FlowModFlags _flags; private String _flowName; private Integer _hardTimeout; //硬超时时间 private FlowId _id; private Integer _idleTimeout; //空闲超时时间 private Instructions _instructions; //指令集,动作或流水线处理 private FlowKey _key; private Match _match; private Long _outGroup; private BigInteger _outPort; private Integer _priority; private Short _tableId; private Boolean _barrier; private Boolean _installHw; private Boolean _strict; OpenFlow协议超时机制简介: 硬超时hard timeout:当该流表项的存在时间超过了预设置的硬超时，流表项就会被交换机从流表中移除。即流表项从交换机移除的绝对时间 空闲超时idle timeout:如果连续idle timeout时间内都没有匹配到这条流表,则交换机会主动将该流表项从流表中移除 MatchBuilder org.opendaylight.yang.gen.v1.urn.opendaylight.flow.types.rev131026.flow用于构建匹配字段 openflow1.3支持的匹配字段包括: Future和ListenableFuture Future是Java中的一个类,具体的作用是接受多线程的执行结果,确保得到的执行结果在使用之前进过检验； ListenableFuture是对java原生Future的扩展增强，帮我们检测Future是否完成了，如果完成了就自动调用回调函数，这样可以减少并发程序的复杂度 PacketProcessingListener openflowplugin定义的处理PacketIn消息的封装 intern() 方法 返回字符串对象的规范化表示形式。 SalFlowService 供RPC调用的服务,openflowplugin提供的,包括增加、删除、更新流表三个方法 nodeconnector、nodeconnectorref分别是？打出来看看？ nodeconnector nodeconnectorref Toaster​ 对Tosster例子的学习. OpenDaylight开发-从Toaster例子学习Rpc,Notification,DataStore ​","categories":[{"name":"SDN","slug":"SDN","permalink":"http://example.com/categories/SDN/"}],"tags":[{"name":"ODL","slug":"ODL","permalink":"http://example.com/tags/ODL/"}]},{"title":"Openflowplugin","slug":"Openflowplugin","date":"2022-09-01T01:42:36.374Z","updated":"2022-10-14T12:56:07.560Z","comments":true,"path":"2022/09/01/Openflowplugin/","link":"","permalink":"http://example.com/2022/09/01/Openflowplugin/","excerpt":"​ 本文记录了Openflowplugin项目的阅读和解析.","text":"​ 本文记录了Openflowplugin项目的阅读和解析. 基础概念 参考文献 OpenflowPlugin源码分析(一至八) 【ODL源码分析01】－openflowplugin be版本连接分析 【ODL源码分析02】－openflowplugin 氧版本连接分析 【ODL源码分析03】－opendaylight neutron项目分析 【ODL源码分析04】－ovsdb 被动连接上报流程 OpenDaylight应用基础开发（感受SDN，介绍OpenFlow，OpenFlowPlugin） 官网文档入口 openflowplugin-sodium High Level Architecture OpenFlowJava:是一个实现OpenFlow编解码器的库，它将OpenFlow消息转换为它们各自的内部表示，反之亦然。 OpenFlowPlugin:终止对 OpenFlow 交换机的会话，提供一个每个交换机的低级OpenFlow服务API(add-modify-flow, delete-flow, etc.) Statistics Manager: 负责从附加的OpenFlow交换机收集统计数据和状态，并将它们存储到ODL中供应用程序使用。 Topology Manager:负责使用 LLDP 发现OpenFlow拓扑，并将其放入ODL中供应用程序使用。 Forwarding Rules Manager:顶层OpenFlow模块，向控制器应用程序公开OF功能，提供应用程序级API。管理 OpenFlow交换机内存和交换机中流程的配置(编程)的主要实体。它还将用户配置与OpenFlowPlugin发现的网络状态进行协调。","categories":[{"name":"SDN","slug":"SDN","permalink":"http://example.com/categories/SDN/"}],"tags":[{"name":"Openflowplugin","slug":"Openflowplugin","permalink":"http://example.com/tags/Openflowplugin/"}]},{"title":"L2switch","slug":"L2switch","date":"2022-09-01T01:42:36.370Z","updated":"2022-10-14T08:39:33.495Z","comments":true,"path":"2022/09/01/L2switch/","link":"","permalink":"http://example.com/2022/09/01/L2switch/","excerpt":"​ 本文记录了对标准L2switch和私有L2switch的阅读和解析.","text":"​ 本文记录了对标准L2switch和私有L2switch的阅读和解析. 基础概念 项目目的：基于MD-SAL架构实现基本的2层交换功能,包括对早先版本的重构,适合学习MD-SAL架构 参考文献: L2switch源码分析（上） L2switch源码分析（下） Dijkstra算法 Xorp官方Github 项目模块： 模块名 作用 Packet Handler 处理上送到控制器的报文,是项目的主要功能 Loop Remover 消除网络中的环路 Arp Handler 处理ARP报文 Address Tracker 学习网络中设备的IP地址和MAC地址,把地址存入datastore中inventory对应节点 Host Tracker 跟踪网络中的主机的拓扑位置 L2Switch Main 根据网络流量下发流表,依赖于上边模块的处理结果 Address Tracker(未改动)addressobserver/*AddressObservationWriter:添加mac地址和ip地址,以及节点的连接关系nodeConnectorRef*/ public void addAddress(MacAddress macAddress, IpAddress ipAddress, NodeConnectorRef nodeConnectorRef) &#123; return; &#125; /*AddressObserverUsingArp:处理收到的ARP包notification,校验后调用 addressObservationWriter.addAddress写入*/ public void onArpPacketReceived(ArpPacketReceived packetReceived) &#123; RawPacketFields rawPacket = null; EthernetPacket ethernetPacket = null; ArpPacket arpPacket = null; addressObservationWriter.addAddress(ethernetPacket.getSourceMac(), IpAddressBuilder.getDefaultInstance(arpPacket.getSourceProtocolAddress()), rawPacket.getIngress()); &#125; /*AddressObserverUsingIpv4:处理IPv4包*/ /*AddressObserverUsingIpv6:处理IPv6包*/ /*AddressTrackerProvider:一般是AddressTracker模块的入口,初始化该模块的功能,初始化过程在Init()中,这个模块涉及notification的发布\\侦听*/ Arp Handler(未改动)​ 项目中由于系统的ip\\mac相对变化不大,所以实际项目中不太需要处理ARP,使用的相关逻辑是私有的,不是标准的,保留这个模块是为以后做准备(删除或扩展).这里最重要的是inventory.InventoryReader方法,私有的处理datastore的方法就是根据它改的,加了功能和过滤. package 内容 core ArpHandlerProvider\\ ArpPacketHandler\\ PacketDispatcher\\ ProactiveFloodFlowWriter flow InitialFlowWriter inventory InventoryReader core:/**ArpHandlerProvider:初始化ArpHandler模块(入口),关闭ArpHandler模块 主要关注Init(),这里判断了ARP是Proactive模式还是Reactive模式(主动与被动模式) Proactive模式主动下发洪泛ARP的流表,Reactive模式下发把ARP报文上送至控制器的流表 前者调用 ProactiveFloodFlowWriter 后者调用InitialFlowWriter 再创建好读datastore、分发包、处理包、notification等对象*/ /**ArpPacketHandler:处理送上来的ARP报文 类成员包括一个PacketDispatcher的对象,用来发包 主要成员方法是onArpPacketReceived,对notification进一步处理*/ public void onArpPacketReceived(ArpPacketReceived packetReceived) &#123; //收到的包经过校验计算、处理后,调用PacketDispatcher把包发出去 packetDispatcher.dispatchPacket(packetReceived.getPayload(), rawPacket.getIngress(), ethernetPacket.getSourceMac(), ethernetPacket.getDestinationMac()); &#125; /**PacketDispatcher:把包发送出去,作为一个功能类定义了几个成员方法,典型的有*/ //把来自ingress节点的载荷payload发出去,按照源mac和目的mac的关系,调用洪泛或单播方法 public void dispatchPacket(byte[] payload, NodeConnectorRef ingress, MacAddress srcMac, MacAddress destMac) &#123; &#125; /**ProactiveFloodFlowWriter:用于L2Switch的proactive模式。在这种模式下， 造成洪泛的流表自动写入每个交换机，发送到控制器的(traffic)流量更少。*/ flow:/**InitialFlowWriter:给所有交换机下发将ARP数据包发送到控制器的流表, 与core.ProactiveFloodFlowWriter相对,有新交换机上线时会自动识别并下发*/ inventory：/**InventoryReader:用于读datastore数据 详解见packethandler.xx.control.inventory.InventoryReader*/ Host Tracker(有小改动)主机上线,处理,完成之后把结果告诉私有模块.私有模块自己维护了一套相关的逻辑. internal(小改动)/**internal: ----ConcurrentClusterAwareHostHashMap:并发集群感知主机host，使用ConcurrentHashMap集合来存放host的数据，提供增删改查之类的方法 ----ConcurrentClusterAwareLinkHashMap:并发集群感知链接link，使用ConcurrentHashMap集合来存放link的数据，提供增删改查之类的方法 ----HostTrackerImpl:是主机追踪模块的入口，包含init()等方法,监听data-tree增加、删除等变化，私有模块是在这里做了改动， 发布了一个notification通知处理结果，是这个模块的主要功能类 ----HostTrackerOperation:是接口，表示对事物的操作 ----OperationProcessor:偏底层的实现,跟ODL的事务\\事务链有关,在这个模块里向其它类提供服务 ----SimpleAddressObserver:基于l2switch地址观测器的简单地址观测器，(具体作用?) */ /**OperationProcessor: */ public class OperationProcessor implements AutoCloseable, Runnable, TransactionChainListener &#123; /**成员对象*/ private static final int NUM_RETRY_SUBMIT = 2; private static final int OPS_PER_CHAIN = 256; private static final int QUEUE_DEPTH = 512; private static final Logger LOG = LoggerFactory.getLogger(OperationProcessor.class); private final DataBroker dataBroker; private final BlockingQueue&lt;HostTrackerOperation> queue; private final AtomicReference&lt;BindingTransactionChain> transactionChain = new AtomicReference&lt;>(); /**构造器*/ /**成员方法*/ onTransactionChainFailed(); onTransactionChainSuccessful(); run(); close(); chainFailure(); enqueueOperation(); submitTransaction(); clearQueue(); &#125; ​ HostTrackerImpl会监听data tree的改变并根据不同的改变类型做出处理并修改数据树,私有模块在这里插入了AddHostBuilder和SayLinkBuilder,他们是由yang文件生成的,用来把ODL的处理结果发布成notification并被私有模块的listener订阅.这样就获取了主机上线、增加连接、删除连接等结果。定义的yang文件在hosttracker\\model\\src\\main\\yang\\host-tracker-service.yang，添加内容如下： notification say-link&#123; leaf message&#123; type string; &#125; leaf linkType&#123; type string; &#125; leaf source&#123; type string; &#125; leaf destination&#123; type string; &#125; &#125; notification add-host&#123; leaf ip&#123; type string; &#125; leaf mac&#123; type string; &#125; leaf ncID&#123; type string; &#125; &#125; /**HostTrackerImpl:*/ public class HostTrackerImpl implements DataTreeChangeListener&lt;DataObject> &#123; /**成员对象*/ private static final int CPUS = Runtime.getRuntime().availableProcessors(); private static final String TOPOLOGY_NAME = \"flow:1\"; private static final Logger LOG = LoggerFactory.getLogger(HostTrackerImpl.class); private final DataBroker dataService; private final String topologyId; private final long hostPurgeInterval;//Purge净化 private final long hostPurgeAge; private final ScheduledExecutorService exec = Executors.newScheduledThreadPool(CPUS);//java提供的线程服务 private final ConcurrentClusterAwareHostHashMap hosts;//自定义的主机host信息集合 private final ConcurrentClusterAwareLinkHashMap links;//自定义的连接Link信息集合 private final OperationProcessor opProcessor;//自定义的模块操作 private final Thread processorThread; private ListenerRegistration&lt;DataTreeChangeListener> addrsNodeListenerRegistration;//连续三句多态写法 private ListenerRegistration&lt;DataTreeChangeListener> hostNodeListenerRegistration;//注册监听器 private ListenerRegistration&lt;DataTreeChangeListener> linkNodeListenerRegistration; /**构造器*/ /**成员方法*/ public void init() &#123; /**起三DataTreeChangeListener监听器*/ &#125; public void onDataTreeChanged(Collection&lt;DataTreeModification&lt;DataObject>> changes) &#123; /**数据树的改变被转在collection集合中,遍历每一个改变并判断改变的类别, 如果是SUBTREE_MODIFIED:不处理 如果是WRITE:调用onModifiedData(identifier, rootNode);这个方法进一步调用了packetReceived方法 如果是DELETE::调用onDeletedData(identifier, rootNode);这个方法进一步调用了packetReceived方法 其它:结束*/ &#125; /**下述两个方法使用的AddHostBuilder和SayLinkBuilder是两个自定义的notification,各自包含数据*/ /**私有模块对这个方法有改动,增加的部分用region包括*/ private void onModifiedData(InstanceIdentifier&lt;?> iid, DataObjectModification&lt;?> rootNode) &#123; final DataObject dataObject = rootNode.getDataAfter(); if (dataObject instanceof Addresses) &#123; packetReceived((Addresses) dataObject, iid); //region:增加通知私有的拓扑模块添加主机 String nc_id =iid.firstIdentifierOf(NodeConnector.class).firstKeyOf(NodeConnector.class).getId().getValue(); Addresses a = (Addresses)dataObject; AddHostBuilder ab = new AddHostBuilder(); ab.setIp(a.getIp().getIpv4Address().getValue()); ab.setMac(a.getMac().getValue()); ab.setNcID(nc_id); notificationService.publish(ab.build()); //endregion &#125; else if (dataObject instanceof Node) &#123; hosts.putLocally((InstanceIdentifier&lt;Node>) iid, Host.createHost((Node) dataObject)); &#125; else if (dataObject instanceof Link) &#123; links.putLocally((InstanceIdentifier&lt;Link>) iid, (Link) dataObject); //region:增加通知私有的拓扑模块添加主机和交换机的连接 Link link=(Link)dataObject; SayLinkBuilder slb = new SayLinkBuilder(); slb.setLinkType(\"onmodified\"); slb.setMessage(link.getLinkId().getValue()); notificationService.publish(slb.build()); //endregion &#125; &#125; /**私有模块对这个方法有改动,增加的部分用region包括*/ private void onDeletedData(InstanceIdentifier&lt;?> iid, DataObjectModification&lt;?> rootNode) &#123; if (iid.getTargetType().equals(Node.class)) &#123; Node node = (Node) rootNode.getDataBefore(); InstanceIdentifier&lt;Node> iiN = (InstanceIdentifier&lt;Node>) iid; HostNode hostNode = node.augmentation(HostNode.class); if (hostNode != null) &#123; hosts.removeLocally(iiN); &#125; &#125; else if (iid.getTargetType().equals(Link.class)) &#123; // TODO performance improvement here InstanceIdentifier&lt;Link> iiL = (InstanceIdentifier&lt;Link>) iid; links.removeLocally(iiL); linkRemoved((InstanceIdentifier&lt;Link>) iid, (Link) rootNode.getDataBefore()); //region:增加通知私有的拓扑模块删除主机和交换机的连接link Link link=(Link)rootNode.getDataBefore(); SayLinkBuilder sb = new SayLinkBuilder(); sb.setLinkType(\"onDeleted\"); sb.setMessage(link.getLinkId().getValue()); sb.setSource(link.getSource().getSourceTp().getValue()); sb.setDestination(link.getDestination().getDestTp().getValue()); notificationService.publish(sb.build()); //endregion &#125; &#125; public void packetReceived(Addresses addrs, InstanceIdentifier&lt;?> ii) &#123; /**最后调用了processHost(opNode.get(), opNodeConnector.get(), addrs);方法*/ &#125; private void processHost(org.opendaylight.yang.gen.v1.urn.opendaylight.inventory.rev130819.nodes.Node node, NodeConnector nodeConnector,Addresses addrs) &#123; /**在这里写到datastore中*/ writeDataToDataStore(linksToAdd, linksToRem); &#125; /**后续的处理方法是增删改查*/ /**关闭模块*/ public void close() &#123; processorThread.interrupt(); this.addrsNodeListenerRegistration.close(); this.hostNodeListenerRegistration.close(); this.linkNodeListenerRegistration.close(); this.exec.shutdownNow(); this.hosts.clear(); &#125; &#125; inventory/**inventory: ------Host:创建主机对象,写明主机对象有的属性和方法 */ util/**util: ------Compare:提供2个比较方法 -------Utilities:公共工具 */ Packet Handler(主要功能)​ Packet Handler负责处理控制器涉及的大部分报文,私有功能的逻辑主要在这里定义.相比标准结构,增加了control、icfp两个文件夹,共有decoder(解码器)文件夹和PacketHandlerProvider类,重点关注control和icfp文件夹,以及私有项目对blueprint的改动,对pom.xml文件的改动. decoder(未改动):​ 对decoder的解析详见ARP流程梳理: package\\class 作用 utils 解码器的工具包 AbstractPacketDecoder 解码抽象类，所有解码器必须继承实现其中方法 ArpDecoder 解码ARP报文 EthernetDecoder 解码以太网帧 IcmpDecoder 解码Icmp报文 Ipv4Decoder 解码Ipv4报文 Ipv6Decoder 解码Ipv6报文,在私有系统中暂时不涉及 PacketHandlerProvider（未改动）：/**PacketHandlerProvider:模块的入口*/ public class PacketHandlerProvider &#123; private static final Logger LOG = LoggerFactory.getLogger(PacketHandlerProvider.class); //不可变集合ImmutableSet ImmutableSet&lt;AbstractPacketDecoder> decoders; //引入Notification服务,在blueprint中引入,是否实现Notification功能,后续实现 private final NotificationProviderService notificationService; //构造器,有参 public PacketHandlerProvider(final NotificationProviderService notificationService) &#123; this.notificationService = notificationService; &#125; //初始化模块,new一堆解码器 public void initiateDecoders() &#123; decoders = new ImmutableSet.Builder&lt;AbstractPacketDecoder>() .add(new EthernetDecoder(notificationService)) .add(new ArpDecoder(notificationService)).add(new Ipv4Decoder(notificationService)) .add(new Ipv6Decoder(notificationService)).add(new IcmpDecoder(notificationService)).build(); LOG.info(\"PacketHandler initialized.\"); &#125; //侦测有解码器对象在,遍历关闭 public void closeDecoders() throws Exception &#123; if (decoders != null &amp;&amp; !decoders.isEmpty()) &#123; for (AbstractPacketDecoder decoder : decoders) &#123; decoder.close(); &#125; &#125; LOG.info(\"PacketHandler (instance &#123;&#125;) torn down.\", this); &#125; &#125; blueprint:packet-handler.xml&lt;!--标准l2switch中的blueprint很简洁,类只注册了入口PacketHandlerProvider,服务只引入了notificationService--> &lt;reference id=\"notificationService\" interface=\"org.opendaylight.controller.sal.binding.api.NotificationProviderService\" /> &lt;bean id=\"packetHandler\" class=\"org.opendaylight.l2switch.packethandler.PacketHandlerProvider\" init-method=\"initiateDecoders\" destroy-method=\"closeDecoders\"> &lt;argument ref=\"notificationService\" /> &lt;/bean> &lt;!--私有项目中对应的blueprint由于增加了功能,注册了新的类,引入了新的服务,略写列在下面--> &lt;reference id=\"dataBroker\" interface=\"org.opendaylight.controller.md.sal.binding.api.DataBroker\"odl:type=\"default\" /> &lt;odl:rpc-service id=\"salFlowService\" interface=\"org.opendaylight.yang.gen.v1.urn.opendaylight.flow.service.rev130819.SalFlowService\"/> &lt;odl:rpc-service id=\"packetHandlerService\" interface=\"org.opendaylight.yang.gen.v1.urn.opendaylight.packet.service.rev130709.PacketProcessingService\"/> &lt;!--私有项目注册了其它入口--> &lt;bean id=\"ControlServiceIml\" class=\"org.opendaylight.l2switch.packethandler.control.service.ControlServiceIml\" init-method=\"init\" destroy-method=\"close\"> &lt;argument ref=\"salFlowService\" /> &lt;argument ref=\"packetHandlerService\" /> &lt;argument ref=\"dataBroker\" /> &lt;argument ref=\"notificationService\" /> &lt;/bean> &lt;bean id=\"MyOdlProvider\" class=\"org.opendaylight.l2switch.packethandler.control.ControlProvider\" init-method=\"init\" destroy-method=\"close\"> &lt;argument ref=\"salFlowService\" /> &lt;argument ref=\"packetHandlerService\" /> &lt;argument ref=\"dataBroker\" /> &lt;argument ref=\"notificationService\" /> &lt;/bean> pom.xml:增加了依赖项​ 增加了依赖项,主要是openflowplugin、snmp、json等方面. control(增加):后端控制器的工作逻辑： package\\class 作用 config 存放系统的配置,提供三种配置Link、Node、Rule，以集合的形式存在总配置对象ConfObject中 entity(实例) 类似于工具类,放了一些功能的实例类,但是大部分代码由于各种原因已经不适用了,保留是因为还没来得及删除或留待以后拓展 flow 包括下发流表的单例,创建\\下发控制器到控制器的初始流表 inventory 保存信息,创建保存信息的数据结构,以及读取ODL内存的功能类 listener 订阅各种notification pathfinding 计算内部\\外部路径 processer 处理ip报文，包括二层、三层，单播、组播 service 给前端提供接口服务 util 工具类 ControlProvider control的入口类,在blueprint中有注册 CustomPacketDispatch 自定义的分发包方法 /**Config:*/ /**在三种配置的上层,建立了三个集合存放不同的配置对象*/ public class ConfObject&#123; public int outer_dpid=-1;//初始化值,-1无效 public List&lt;LinkConfInfo> link=new ArrayList&lt;>();//存放连接配置 public String controller; public HashMap&lt;String,NodeConfInfo> nodeConfInfo=new HashMap&lt;>();//存放节点配置 public List&lt;RuleConfInfo> rules=new ArrayList&lt;>();//存放规则配置 &#125; /**下面三类配置类都比较简单,就是成员变量+构造器*/ public class LinkConfInfo&#123; public int port; public String type; public String channel; public int interval;//端口之间同步的间隔 /**构造器*/ &#125; public class NodeConfInfo&#123; public String node_level; public String node_num; /**构造器*/ &#125; /**所谓规则Rule就是从这个口到那个口\\这个地址到那个地址走哪个信道?优先级多少?之类的可配置的选项*/ public class RuleConfInfo&#123; public String source_ip; public String source_mac; public int des_port_num; public int protocol_type; public int priority; public int channel; /**构造器*/ &#125; /**entity: ------flow:早期用于下流表的代码,由于改需求已经不用了,暂时没删除,供参考 ------highlight:控制拓扑有流量时高亮功能的代码,,现在是由自己的前端控制,已经不用了,供参考 ------host:存放外网交换机的dpid和mac,包括源和目的,暂时用不上 ------internal:处理车内终端和车内连接关系 ------multicast(多播):用于缓存组播处理后的结果,这部分在使用 ------path:包括路径对象,和路径的配置等对象,相当于定义了一些跟路径有关的数据结构 ------rule:现在用其他方法配规则,已经不用了 ------Narrowband.java(窄带):读窄带端机的信息,ip\\掩码\\下一跳等*/ /**flow:包含4*xx.java*/ //自定义动作项 public class CustomActionItem&#123; public int out_put; /**构造器*/ &#125; //自定义匹配项 public class CustomMatchItem&#123; public String s_ip; public String d_ip; public String s_mac; public String d_mac; public int protocol_num = -1; public int l4_source_num= -1; public int l4_destination_num = -1; /**标准配置*/ toString(); equals(); hashCode(); /**构造器*/ &#125; //说明了一条流表的基本状态 public class FlowObject&#123; public FlowStatus flowStatus; public boolean chao_duan_bo=false; public List&lt;Path> in_car_paths=new ArrayList&lt;>();//车内路径 public List&lt;Path> external_paths=new ArrayList&lt;>();//车间路径 public boolean onSameCar=false; public int onSameCar_dpid = -1; //每个交换机对应一个Action列表 public HashMap&lt;Integer,List&lt;CustomActionItem>>action_map=new HashMap&lt;>(); public List&lt;Integer> rule_list=new ArrayList&lt;>(); public void clear()&#123;&#125; &#125; // public enum FlowStatus&#123; NO_ARP,//无arp响应 NO_BETWEEN_PATH,//无车间路径 IN_CAR_FLOW,//车内的流表 BETWEEN_FLOW//车间的流表 &#125; /**flow: ----FlowWriter.java:下发流表的功能类,调用salFlowService服务，包括创建、下发、删除流表、创建动作和指令等 ----InitialC2CFlowWriter.java:创建系统启动时下发的流表,C2C:一个控制器到另一个控制器*/ public class FlowWriter&#123; //成员对象 private static final FlowWriter instance=new FlowWriter();//饿汉单例,别人不能new它,只能调用它 private SalFlowService salFlowService ; //构造器 private FlowWriter()&#123;&#125;//饿汉单例 //getter setter方法 //成员方法 addFlow();/**包括:_inCar,_CHAODUANBO,_multicast,SegmentedPath(分段路径), */ createFlow();/**包括:CHAODUANBO,_multicast,remove*/ removeFlow();/***/ createInstructions();/***/ createAction();/**SetFieldDestinationMacAddress,OutPut,*/ getmaskIP();//处理掩码和IP &#125; public class InitialC2CFlowWriter implements DataTreeChangeListener&lt;node>&#123; //成员对象 private static final String FLOW_ID_PREFIX= \"l2switch-\"; private static final int C2C_ETHER_TYPE=2320;//私有的以太网类型,0x0910 private final ExecutorService initialFlowExecutor=Executors.newCachedThreadPool(); private final SalFlowService salFlowService ; private short flowTableId=0; private int flowPriority = 100; private int flowIdleTimeout = 0; private int flowHardTimeout = 0; private final AtomicLong flowIdInc=new AtomicLong(); private final AtomicLong flowCookieInc=new AtomicLong(0x2b0000000000000L); //构造器 public InitialC2CFlowWriter(SalFlowService salFlowService ); //成员方法 onDataTreeChanged(Collection&lt;DataTreeModification&lt;Node>> changes) ; //内部成员类 public class InitialFlowWriterProcessor implements Runnable&#123; addInitialFlows(); getTableInstanceId(); getFlowInstanceId(); createControllerToControllerFlow(); createDefaultFlow(); getSendToControllerAction(); writeFlowToController(); &#125; &#125; /**inventory: ------FlowDB: 保存路径,包括源和目的在同一台车或不在同一台车,由于改需求,已经不用了,不需要保存路径了 ------InternalDB:给一台车本身的大部分配置都建好集合,从配置文件或其它渠道拿到数据后再存到里面 ------InventoryReader:参考arphandler.inventory.InventoryReader写的读取ODL内存的功能类,还命名为InventoryReader,变化不大 ------RuleDB:保存规则,配置信息等,现在已经不用这种方式配置规则了,只保留了ALL_CHANNEL_LIST,写死5种信道 */ /**FlowDB: */ public class FlowDB&#123; //源和目的在同一台车,保存转发端口就可以 updateInCarFlowMap_SameCar(int dpid,String s_ip,String d_ip,int output_port); //源和目的不在一个车内,需要保存路径计算的结果,就是一个List集合 updateInCarFlowMap_Path(String s_ip,String d_ip,List&lt;Path> paths); &#125; /**InternalDB: */ public class InternalDB&#123; /**成员对象*/ //new一个空的配置对象 public static ConfObject confObject = null; //外部交换机的dpid public static int EXT_SWITCH_DPID = -1; public static HashMap&lt;Integer,Boolean> EXT_NODE_PORT_STATUS=new HashMap&lt;>(); //网关 //车间连接端口:从配置文件中读取车是通过哪些端口连起来的 //端机MAC: //窄带端机都挂载在哪个交换机下面 //有哪些车内交换机:内网\\外网交换机都读 //车内主机mac: //本车交换机mac: //本车的角色配置: &#125; /**InventoryReader: */ public class InventoryReader implements DataTreeChangeListener&lt;DataObject>&#123; /**成员对象*/ private static final Logger LOG=LoggerFactory.getLogger(InventoryReader.class); private final Databroker databroker; private final HashMap&lt;String,List&lt;NodeConnectorRef>> controllerSwitchConnectors; private final HashMap&lt;String,List&lt;NodeConnectorRef>> switchNodeConnectors; private final List&lt;Registration> listenerRegistrationList = new CopyOnWriteArrayList&lt;>(); private volatile boolean refreshData = false;//使用volatile关键字会强制将修改的值立即写入主存,任意线程修改了这个值,对其它线程立即可见 private final long refreshDataDelay = 20L; private volatile boolean refreshDataScheduled = false; private final ScheduledExecutorService nodeConnectorDataChangeEventProcessor=Executors.newScheduledThreadPool(1); /**构造器*/ /**getter、setter方法*/ public void setRefreshData(boolean refreshData); /**成员方法*/ public void registerAsDataChangeListener(); public void onDataTreeChanged(); public void close(); //读取data tree以查找有关节点node和节点连接器NodeConnectors的信息。为给定交换机创建NodeConnector的List集合。还确定每个NodeConnector的STP状态。 public void readInventory(); &#125; /**RuleDB: */ public class RuleDB&#123; /**成员对象*/ public static List&lt;Integer> ALL_CHANNEL_LIST = Stream.of(4,3,2,1,0).collect(Collectors.toList()); &#125; /**listener:这个package大部分都在用的,订阅了多种notification，相当于notification触发了listener的进一步处理 SegmentedPathCalculationListener和TopoChangeNotificationListener功能最为重要 ------ARPlistener:订阅arp解码器的notification,进一步处理arp报文 ------C2CPacketListener:监听C2C报文,并对收到的报文分情况判断,解析,再发送出去,其中的反向流表已经没有这个概念了, 由于代码调整,目前只有组播流表下发还在使用 ------HostInfoListener:监听主机上线,发现上线后获取主机的信息,存储主机的信息,再完成洪泛主机的存在, 下发必要流表等功能,包括免费ARP报文;主机下线后删除相关的信息,以及处理其他,SayLink代表Link发生变动 ------LldpListener:收到LLDP报文,分析\\过滤掉不要的报文,处理LLDP报文发现的连接关系,生成流表之类的 ------SegmentedPathCalculationListener:计算外部分段路径,接收lsa变动规则配置通知,进行路径重算并下发车间流表 ------TopoChangeNotificationListener:监听拓扑变化,处理拓扑变化带来的后续动作,增删节点\\设备,洪泛信息,重算路径等等 */ /**HostInfoListener,实现的接口跟addhost和saylink等都是yang语言自己定义的*/ public class HostInfoListener implements HostTrackerServiceListener&#123; public SalFlowService salFlowService；//说明需要下发流表 public CustomPacketDispatcher customPacketDispatcher；//说明需要发送报文 public HostInfoListener(SalFlowService salFlowService,CustomPacketDispatcher customPacketDispatcher)&#123; this.salFlowService=salFlowService; this.customPacketDispatcher=customPacketDispatcher; &#125; /**这里订阅了HostTracker中添加的两个Notification:主机信息、主机和交换机连接的信息*/ public void onAddHost(AddHost notification)&#123; String ip=notification.getIp(); if(ip.equals(\"0.0.0.0\")) return;//0.0.0.0ip代表本机或无法识别的设备 String mac = notification.getMac(); String[] strs = notification.getNcID.split(\":\"); //把NcID的内容根据\":\"分隔开,然后依次装到数组中，其实就是openflow:22:26 int dpid = Integer.valueof(strs[1]);//数组索引1是dpid,指的是连在哪台设备上,2是端口 int output_port = Integer.valueof(strs[2]); if(InternalDB.EXTERNAL_LINK_PORTS.contains(output_port)) return;//发现的端口是车间连接的端口,这个端口不处理lldp报文,从配置文件获取,不应该连主机 if(ip.equals(InternalDB.GATEWAY_IP)) return;//发现的是网关 /**在控制台输出发现的主机,目前不是log*/ System.out.println(String.format(\"发现主机:ip|%s mac|%s dpid|%s 端口|%s\",ip,mac,dpid,output_port)); /**InternalDB中定义了集合HOSTS存储信息,数据格式是(mac,host)的键值对,数据类型是HostInfo类型， 新建一个HostInfo类型的对象host,到HOSTS索引本次主机追踪发现的mac地址，并把结果存入host中， 如果host为空，代表这是一个没有发现过的主机，新建对象并且存入HOSTS， 如果host有数据，代表这是一个之前发现过的主机，更新数据即可 */ HostInfo host = InternalDB.HOSTS.get(mac); if(host==null)&#123; Set&lt;String>ipSet = new HashSet&lt;>(); ipSet.add(ip); host = new HostInfo(ipSet,dpid,mac,output_port); InternalDB.HOSTS.put(mac,host); &#125; else&#123; host.getIp().add(ip); host.setDp_id(dpid); host.setOut_port(output_port); &#125; &#125; /**洪泛信息: icfpv2Target是packethand中icfp.master中的一个类,相当于icfp诸多功能的一个入口 icfpv2Target.icfp_add_host方法调用的icfp.icfp_add_host,又进一步调用get_peer_manager().add_host() 这里应该不是添加到ODL内存中,而是添加到私有维护的模块中 后续用法原理类似*/ ControlProvider.icfpv2Target.icfp_add_host(ip,mac,true); /**免费arp:主机请求自己的mac地址,不期望得到回应, 作用:1.避免有人跟自己有相同的ip2.自己的mac更改时,可以告诉别的设备更改缓存表*/ SendFreeARP2Transit(ip,mac); /**下发外网交换机到pc的流表*/ UnicastUtil.addFlow_ExternalToPC(ip,mac,dpid,output_port); /**洪泛主机连接信息*/ Link addLink = new Link(mac,(short)host.getDp_id()); ControlProvider.icfpv2Target.icfp_add_inner_topology(addLink.get_d_id(),addLink,true); /**处理过程跟onAddHost类似,为提高阅读速度,不详细说明*/ public void onSayLinkl(SayLink notification)&#123; &#125; /**这里最后调用了CustomPacketDispatcher中的方法发出报文*/ public void SendFreeARP2Transit(String ip,String mac)&#123;&#125; &#125; /**FlowTopologyDiscoveryListener是openflowplugin.model定义的yang文件生成的接口,这里用maven依赖跨工程调用了*/ public class LldpListener implements FlowTopologyDiscoveryListener&#123; /**重写了接口中的四个方法,其中只有第一第三有内容*/ onLinkDiscoverd(); onLinkOverutilized();//连接重复 onLinkRemoved(); onLinkUtilizationNormal();//链接使用正常? &#125; /**pathfinding: ------ExtPathFinder: ------InnerPathFinder: */ /**ExtPathFinder: 计算外部路径*/ public class ExtPathFinder&#123; /**只包括一个成员方法:计算符合ruleList规则的node_map节点中,从start_node_id到end_node_id的路径, 返回的结果是Path_Result类型的,包括开始节点、结束节点、距离、路径，共四个属性*/ public static Path_Result calculate(int start_node_id,int end_node_id,List&lt;Integer> ruleList, HashMap&lt;Integer,T_Node> node_map)&#123; /**这里的原理就是迪杰特斯拉算法,ruleList相当于是计算时的限制条件,后续要详细梳理以下它的实现过程*/ &#125; &#125; /**InnerPathFinder: 计算内部路径*/ public class InnerPathFinder&#123; public static Path_Result calculate(int start_node_id,int end_node_id,HashMap&lt;Integer,T_Node_InCar> node_map)&#123; /**思路跟外部路径类似,但是涉及的计算对象和条件不同,也是返回一个Path_Result类型结果*/ &#125; &#125; /**processor：这两类的结构基本一致，梳理清Ipv4Processor即可 ------Ipv4Handler:处理被搬移到二层的ip报文，暂时不用，优先使用Ipv4Processor ------Ipv4Processor:处理三层单播和组播 */ /**service:用于给前端提供服务，返回接口调用的内容，对于学习后端控制逻辑来说这部分不重要 ------entity(package):定义了许多数据结构类，一级拓扑、二级拓扑、连接，状态等等 ------ControlServiceImpl:服务功能的具体实现 ------HighlightKey:跟信道高亮有关 */ /**util:工具包 ------byteencode:转换数据格式的 ------flowcapablenodemapping:把lldp的notification转成某个类？ ------instanceidentifierutils:ODL提供的，被复制到这里 ------multicastutil:组播，包括构建组播的流表、报文等等 ------unicastutil:单播，功能同上 */ /**ControlProvider: */ public class ControlProvider&#123; /**成员对象*/ private final DataBroker dataService； private final SalFlowService salFlowService； private final NotificationProviderService notificationService； private final PacketProcessingService packetProcessingService； public static int PATH_MODE = 1；//0:源节点计算整条路径 1:各节点分别计算 //多态写法 private Registration initialFlowWriterListenerReg; private Registration arpHandlerRegistration; private Registration unicastArpHandlerRegistration; private Registration ipv4HandlerRegistration; private Registration c2cListenerRegistration; private Registration lldpListenerRegistration; private Registration segmentedPathProcessorRegistration; private Registration icfpListenerReg; public static Icfpv2Target icfpv2Target; /**构造器*/ /**成员方法*/ //从文件中读取系统配置,conf.json public void readconf(); //初始化:把该模块涉及到的对象\\多态全new出来,并传给成员对象,包括调用注册类Registration多态实现类等 public void init() throws IOException&#123;&#125;; //关闭 public void close(); &#125; /**CustomPacketDispatcher: 自定义的分发包方法,不同需求的发包方法都定义在这 */ public class CustomPacketDispatcher&#123; /**成员对象*/ private InventoryReader inventoryReader; private PacketProcessingService packetProcessingService; /**getter,setter方法*/ /**没写构造器,默认是无参构造器*/ /**成员方法*/ //发送包，调用了底层的TransmitPacketInput，以及Future public void sendPacketOut(byte[] payload,NodeConnectorRef ingress,NodeConnectorRef egress)； public void sendData2Port(byte[] data,String node_id,int outport_port); public void floodArpRequest(String s_ip,String d_ip,String s_mac,NodeConnectorRef nodeConnectorRef); public void sendArpRequest(String s_ip,String d_ip,String s_mac,String nodeId,List&lt;InternalLink> links,NodeConnectorRef origIngress,boolean external); &#125; icfp(增加):​ 私有协议名为智能连接转发协议,简称ICFP,包括三个部分,代码主体来自对C++OSPF的移植,选择其中有用的部分移植到了java环境,源代码Xorp官方Github: icdp:智能连接发现协议,车内链路信息搜集 icgp:智能连接组播组协议,组播路由信息搜集 icsp:智能连接切换协议,车间链路信息搜集 package\\class 作用 icsp 智能连接切换协议,车间链路信息搜集 igmp 组播的因特网组管理协议，来自floodlight master timer utils 工具包 /**icsp: ------area: ------common: ------decoder: ------entity: ------enumtype: ------lsa: ------packet: ------peer: */ /**igmp: ------ ------ ------ ------ ------ ------ ------ ------ ------ ------ ------ ------ ------ */ /**master: ------icfp: ------icfpv2target: ------initialicfpflowwriter: ------proactivefloodflowwriter: */ /**timer: ------ ------ ------ ------ ------ ------ */ /**utils: ------ ------ ------ ------ ------ */ loopremover(暂不使用)​ loopremover模块使用stp协议消除环路,生成无环拓扑图,在目前的私有项目中不考虑这一部分,因为机动通信系统的组织架构天然是胖树结构没有环,甚至天然是路径树,所以不需要去除环路的部分,不过为丰富代码的健壮性,这个功能将来需要补充.loopremover的结构跟l2switch-main类似: loopremoverprovider/**loopremoverprovider:模块的入口*/ public class LoopRemoverProvider &#123; /**成员对象*/ /**构造器*/ /**init:如果isIsInstallLldpFlow配置为true,则调用InitialFlowWriter下发初始流表 调用TopologyLinkDataChangeHandler监听拓扑数据变化,等待graphrefreshdelay(环路计算间隔时间) 后调用NetworkGraphImpl对拓扑去环路*/ /**close*/ &#125; flow/**flow: ------InitialFlowWriter:在所有交换机上添加一个将所有LLDP数据包发送到控制器的流。注册为ODL 资源清册侦听器，以便在添加新节点（即交换机）后添加流。 InitialFlowWriterProcessor中包含添加流表、创建流表、写入流表等方法 */ topology/**topology:处理拓扑,这里只简单的分析一下networkgraphimpl ------networkgraphimpl:去除环路的类,内部使用Jung图库维护图，并使用Dijkstra算法以最佳方式返回最短路径。 ------networkgraphservice:上述类的接口 ------topologylinkdatachangehandler:订阅了拓扑变化的notification,并处理拓扑变化 */ /**默认注释掉了迪杰特斯拉算法,都是用的jung库中的方法计算的*/ public class NetworkGraphImpl implements NetworkGraphService &#123; /**成员对象*/ /**成员方法*/ public synchronized void addLinks(List&lt;Link> links); private boolean linkAlreadyAdded(Link link) ; public synchronized void removeLinks(List&lt;Link> links); public synchronized void clear() ; /**这个方法中调用了jung库中的虽小生成树算法:PrimMinimumSpanningTree,在这里去的环*/ public synchronized List&lt;Link> getLinksInMst() &#123; List&lt;Link> linksInMst = new ArrayList&lt;>(); if (networkGraph != null) &#123; PrimMinimumSpanningTree&lt;NodeId, Link> networkMst = new PrimMinimumSpanningTree&lt;>( DelegateTree.&lt;NodeId, Link>getFactory()); Graph&lt;NodeId, Link> mstGraph = networkMst.apply(networkGraph); Collection&lt;Link> mstLinks = mstGraph.getEdges(); linksInMst.addAll(mstLinks); &#125; return linksInMst; &#125; public synchronized List&lt;Link> getAllLinks(); &#125; 参考文献： 最小生成树MST（Minimum Spanning Tree)-普里姆(Prim)算法 util/**util:工具类 ------InstanceIdentifierUtils: */ l2switch-main(不使用)​ 这个模块在标准项目中是主要服务的提供者，由L2SwitchMainProvider控制工作流程.私有项目自己定义了更复杂的工作流程，所以在blueprint.xml中彻底把这个模块关闭. ​ l2switch-main表现出来的运行逻辑是比较清晰的,入口根据配置文件的不同模式给交换机下发不同的流表,并且在下发流表的过程中订阅了notification,能够与之前梳理的decoder对应上,给出了inventoryreader,提供了操作ODL内存的方法,用到了yang模型生成的工具.对一个交换机而言,正确的转发报文已经是非常基础的内容了,通过梳理l2switch-main对ODL简单控制逻辑已经比较了解了.这里用这个模块顺便总结一下如何快速阅读一个ODL模块: l2switch-impl.xml​ 首先阅读blueprint.xml能够迅速理清这个模块： 引用哪些服务，比如dataBroker和notification等 发布哪些服务，比如rpc和notification等 模块的入口，在中写明入口类及其初始化方法和关闭方法,一般是init\\start和close yang​ 然后阅读yang文件,yang文件定义了这个模块功能模型,能迅速明白这个模块用到的功能,yang文件经过yangtools生成的工具类在如下路径,模块内的方法会调用到这些工具类,有的模块有多个位置放yang文件. target/generated-sources/mdsal-binding/org/opendaylight/yang/gen/v1/urn/opendaylight/l2switch/l2switch/config/rev140528 #l2switch-config.yang定义了l2Switch的一系列默认配置,并在入口类被读取到方法中 L2SwitchMainProvider​ 最后从模块入口阅读具体代码: /**L2SwitchMainProvider的结构比较简单,大概就是读取yang定义的配置*/ public class L2SwitchMainProvider &#123; /**成员对象*/ /**有参构造器*/ /**init方法:把yang文件中的配置读取到FlowWriterServiceImpl的对象中 ,初始化InventoryReader 如果配置文件中是isIsInstallDropallFlow,就调用initialflowwriter下发dropall流表 如果isIsLearningOnlyMode为false,就调用ReactiveFlowWriter下发流表/ /**close方法*/ &#125; flow/**flow: ------flowwriterservice:接口,规定了两个添加flow的方法 ------flowwriterserviceimpl:实现上面接口,负责添加、创建、下发流表 ------initialflowwriter:创建dropall流表 ------reactiveflowwriter:动态的创建流表，订阅了onArpPacketReceived的notification */ inventory/**inventory: ------inventoryreader:提供读取ODL内存的方法 */ util/**util: ------InstanceIdentifierUtils:工具方法 */","categories":[{"name":"SDN","slug":"SDN","permalink":"http://example.com/categories/SDN/"}],"tags":[{"name":"L2switch","slug":"L2switch","permalink":"http://example.com/tags/L2switch/"}]},{"title":"Bug收集","slug":"Bug收集","date":"2022-09-01T01:42:36.369Z","updated":"2022-09-05T08:04:21.712Z","comments":true,"path":"2022/09/01/Bug收集/","link":"","permalink":"http://example.com/2022/09/01/Bug%E6%94%B6%E9%9B%86/","excerpt":"​ 本文整理收集了调试过程中遇到的Bug和对应的解决方法，供调试时参考.","text":"​ 本文整理收集了调试过程中遇到的Bug和对应的解决方法，供调试时参考. 不同package下同名方法供需错误​ 在ODL中，由于版本更迭，许多不同名字的package中包括了相同名字的方法，在导入ODL包的过程中就有可能出现下图的错误，简单解释就是这里需要白字package中的方法（Required type）但是我们却导入了红字package中的方法（Provided）;唯一的解决办法:就是把涉及的package梳理清楚，把引用关系对应上，在LLDP2Controller实验中出现了这个错误,已解决. findbugs-maven-plugin:x.x.x:check​ maven编译过程中有可能会出现findbugs-maven-plugin:x.x.x:check报错,这是由于ODL项目默认继承了findbugs插件来检查工程可能出现的一些错误,我们编写的代码不符合插件规则就会报错,解决办法是:在…\\impl\\pom.xml文件中把findbugs-maven-plugin插件改为false,已解决. spotbugs-maven-plugin：​ spotbugs和findbugs是类似的插件，有顺承关系，解决办法是在…\\parent\\pom.xml中把spotbugs-maven-plugin插件改为false,已解决. ​ 也出现过修改为false仍然编译不通过的情况,暂未解决 mininet连不上karaf​ 在使用mininet配合实验的过程中,出现了在mininet能ping通宿主机的情况下无法连接到控制器的问题.解决办法: 使用项目原型模板生成的空项目骨架,不具备连接交换机的能力,因此需要添加包含对应功能的features，我这里添加了features-openflowplugin和features-l2switch,其实大部分功能都包含在features-openflowplugin里面,安装features后手动feature:install一下.查看在target&#x2F;assembly&#x2F;system&#x2F;org&#x2F;opendaylight目录下是否有对应文件夹,有的话代表编译成功. 安装对应功能后,必须保证安装mininet的虚拟机和宿主机能够连通,这里的连通不只是ping通,在允许应用程序通过windows防火墙里设置允许程序通过时,既要允许VMware的程序,也要允许Java.exe的进程,因为Karaf在windows资源控制器里表现为Java进程, 之前只保证了虚拟机可以通过,没有设置Java,导致上述bug.同时也要关闭虚拟机防火墙,一般虚拟机默认关闭防火墙的. 如果还是连不上,建议直接彻底关闭防火墙. mininet查看Open vSwitch中的流表时出错​ 使用下述命令构建mininet网络仿真时: sudo mn --controller=remote,ip=192.168.0.10,port=6633 --topo=tree,2 --switch ovsk,protocols=OpenFlow13 ​ 出现如下图错误: ​ 原因在于使用的OpenFlow协议版本不对,解决办法: 去掉--switch ovsk,protocols=OpenFlow13 设置mininet的默认OpenFlow版本为13 解决mininet连接bug后，又出现了连接不上的情况​ 在ProjectNotification2工程中关闭防火墙之后实现了mininet的连接，但是在把LLDPToController功能添加到该项目时，又出现了连接不上的现象，在把增加的功能去掉后，又能连接上.推测是两个项目的pom.xml文件的依赖出现了冲突,导致Karaf启动不起来,具体表现为:1.ctrl +d关不掉进程 2.查询不到6633端口 projectstructure有误​ 某些xxx.java文件比如LLDP2ControllerProvider不能正确被IDEA识别，一般的解决方法有,推荐由上至下排查: 检查用IDEA打开项目时,是否打开的是跟.idea文件夹并列的项目,有时上层文件夹跟项目名一致,会出现打开错误 进入File-Project Structure-Modules重新设置一下包的mark 重启IDEA，然后重新编译安装项目 重启IDEA，使用maven-Reload All Maven Projects 清掉后台所有内容，重启电脑","categories":[{"name":"SDN","slug":"SDN","permalink":"http://example.com/categories/SDN/"}],"tags":[{"name":"Bug","slug":"Bug","permalink":"http://example.com/tags/Bug/"}]},{"title":"工具Utils","slug":"工具Utils","date":"2022-08-09T10:48:22.391Z","updated":"2022-09-26T03:12:19.031Z","comments":true,"path":"2022/08/09/工具Utils/","link":"","permalink":"http://example.com/2022/08/09/%E5%B7%A5%E5%85%B7Utils/","excerpt":"​ 本文记录了软件学习过程中用到的工具类知识点.","text":"​ 本文记录了软件学习过程中用到的工具类知识点. 数据格式JSON JSON: JavaSctipt Object Notation,JavaSctipt 对象表示法 [[图灵程序设计丛书].JSON必知必会](https://pan.baidu.com/s/1UoHP8BiumEt70aSVyhv7dQ提取码：3ir5 )：基础语法1-4章 /**键值对格式: \"名称\":值 名称需要始终被双引号包裹,虽然语法允许,但是建议不要使用空格和单引号、撇、点等特殊字符. 值可以是数字、字符串、数组、对象等数据类型，不是必须被双引号包裹*/ \"animal\":\"cat\" /**Json以对象为单位,构建方式就是在键值对两侧写上花括号,一个对象里,键值对用逗号分隔*/ &#123;\"animal\":\"cat\",\"number\":3&#125; /**原始数据类型: 1.数字:整型、浮点、定点 2.字符和字符串 3.布尔:只能小写 4.null:只能小写 复合数据类型: 1.枚举:数组,可以使用多维数组 2.对象*/ /**枚举*/ [\"cat\",\"dog\",\"tiger\"] /**对象*/ &#123;\"animal\":\"cat\",\"number\":3&#125; /**Json可以嵌套*/ &#123; \"person\":&#123; \"name\":\"Simonck\" \"height\":173 \"hair\":&#123; \"color\":\"red\" \"length\":\"short\" &#125; \"eyes\":\"black\" &#125; &#125; /**Json也使用转义字符: 反斜杠\\+字符*/ &#123;\"location\":\"c:\\\\Hexo\"&#125; /**Json验证:Schema,第一个键值对名称必须为 \"$schema\" ,值是一个schema文件 第二个键值对应该是schema文件的标题 第三个键值对名称为 \"propertites\" ,值为这个Json文件想要的格式 第四个键值对名称为 \"required\" ，值为必填项，注意包含的\"description\"不必须 Schema可以规定的内容还很多，包括字符串长度，数字范围，正则表达式等等，这里不展开*/ &#123; \"$schema\":\"http://json-schema.org/draft-04/schema#\" \"title\":\"cat\" \"propertites\":&#123; \"name\":&#123; \"type\":\"string\" &#125; \"age\":&#123; \"type\":\"number\" \"description\":\"Your cat`s age\" &#125; \"declawed\":&#123; \"type\":\"boolean\" &#125; \"size\":&#123; \"type\":\"string\" \"description\":\"Your cat`s size\" &#125; &#125; \"required\":[ \"name\",\"age\",\"declawed ] &#125; /**这个Json文件符合上述schema*/ &#123; \"name\":\"jack\" \"age\":2 \"declawed\":false &#125; XML [XML入门经典（第5版）](https://pan.baidu.com/s/1l8uOjScZA3tFntH4UTZi-A提取码：gmy9 )基础语法：2-4章 [XML基础教程（第二版）](https://pan.baidu.com/s/1PLCv0MfDOhE7eYo9OXAykg提取码：qqxx [) W3school:xml XML 教程 &lt;!--xml序言+独立声明-->&lt;!--注意linux还是Windows格式的换行符--> &lt;?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"yes\"?> &lt;!--创建元素的方式--> &lt;!--标准元素,有内容--> &lt;myelement>code&lt;/myelement> &lt;!--自封闭元素,没有内容--> &lt;myelement/> &lt;!--四种命名方式--> &lt;!--大驼峰--> &lt;MyElement/> &lt;!--小驼峰--> &lt;myElement/> &lt;!--下划线--> &lt;my_element/> &lt;!--连字符--> &lt;my-element/> &lt;!--一个文档只能有一个根元素--> &lt;root> &lt;!--元素中可以添加属性:属性就是(名称-值)--> &lt;myelement myfirstattribute=\"one\" mysecondattribute='two' mythirdattribute=' '>&lt;/myelement> &lt;!--元素和属性均可包括文本--> &lt;myelement>Here is a test&lt;/myelement> &lt;!--元素和属性都可以用来包装数据--> &lt;!--元素--> &lt;user> &lt;firstname>Yu-Ang&lt;/firstname> &lt;lastname>ZHU&lt;/lastname> &lt;/user> &lt;!--属性--> &lt;user firstname=\"Yu-Ang\" lastname=\"ZHU\" /> &lt;user firstname=\"Yu-Ang\" lastname=\"ZHU\">&lt;/user> &lt;!--处理指令--> &lt;?xml-stylesheet type=\"text/xsl\" href=\"appUsers.xslt\"?> &lt;!--CDATA节,允许在xml文件中插入纯文本--> &lt;!--格式: &lt;![CDATA[文本内容]]> --> &lt;user> &lt;![CDATA[这里写的内容会被当做纯文本处理]]> &lt;/user> &lt;!--通过向元素中添加特殊的属性来决定如何处理空白符--> &lt;!--保留空白符--> &lt;user xml:space=\"preserve\"/> &lt;!--默认处理空白符--> &lt;user xml:space=\"default\"/> &lt;!--命名空间：理解为Java中的package,大小写敏感--> &lt;!--命名空间：建议使用URL或者URN命名规范，这两个合称URI--> &lt;!--URL--> [Scheme]://[Domain][:Port]/[Path]?[QueryString]#[FragmentId] &lt;!--URN--> urn:[namespace identifier]:[namespace specific string] &lt;!--声明命名空间的方法一：默认命名空间,希望整个文档都属于这个空间--> &lt;root xmlns = \"http://wrox.com/namespace/app/config\"> &lt;firstname>Yu-Ang&lt;/firstname> &lt;lastname>ZHU&lt;/lastname> &lt;/root> &lt;!--root元素中的所有子元素都属于这个命名空间,但是属性不属于这个空间--> &lt;!--即:默认命名空间仅针对元素--> &lt;!--给属性分配命名空间需要显示定义,即前缀名,声明命名空间的方法二--> &lt;!--给命名空间一个前缀名xx,并且把元素分配给该空间--> &lt;xx:user xmlns:xx = \"http://wrox.com/namespace/app/config/xx\"> &lt;firstname>Yu-Ang&lt;/firstname> &lt;lastname>ZHU&lt;/lastname> &lt;/xx:user> &lt;!--把属性也分配给命名空间--> &lt;user xx:firstname=\"Yu-Ang\" xx:lastname=\"ZHU\" /> &lt;user xx:firstname=\"Yu-Ang\" xx:lastname=\"ZHU\">&lt;/user> &lt;!--使用&#123;URI&#125;+元素名唯一标记一个元素--> &#123;http://wrox.com/namespace/app/config&#125;root &lt;/root> Maven参考文献 [动力节点：maven入门](https://pan.baidu.com/s/10avLNviwoYM7id_1OAQwPQ提取码：y6no [) 动力节点：maven视频 mvn dependency:tree：梳理项目依赖关系 pom.xml解析​ maven使用xml语法定义了一套标签,这里指出这些标签的常用含义,特殊用法、特殊标签不包括在内. &lt;!--POM.xml根元素是project，声明整个文件都属于这个命名空间，声明其它命名空间的前缀， xsi:schemaLocation不用理解,4.0.0版本是唯一同时支持maven2和maven3的版本--> &lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://maven.apache.org/POM/4.0.0/xxx\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0/xxx/yyy\"> &lt;modelVersion>4.0.0&lt;/modelVersion> &lt;!----> &lt;>&lt;!---->&lt;/> &lt;!--basic基本元素:前三项必须存在，有父pom时可以不重复书写 --> &lt;groupId>&lt;/groupId> &lt;artifactId>&lt;/artifactId> &lt;version>&lt;/version> &lt;packaging>&lt;!--声明打包的类型：默认jar，还有pom、rar等-->&lt;/packaging> &lt;classifier>&lt;!--区分同一POM构建的不同工件artifact，若存在，写在artifact的版本号之后-->&lt;/classifier> &lt;type>&lt;!--被依赖对象的包的格式，默认jar-->&lt;/type> &lt;scope>&lt;!--表示这个依赖对象的作用范围，有5类-->&lt;/scope> &lt;optional>&lt;!--表示别的项目依赖这个项目时，是不是必须安装这个依赖-->&lt;/optional> &lt;exclusions>&lt;!--排除掉你不想依赖的对象，在这里填上坐标或通配符*-->&lt;/exclusions> &lt;dependencies>&lt;!--引入依赖包-->&lt;/dependencies> &lt;parent>&lt;!--这个项目继承的父项目的坐标-->&lt;/parent> &lt;dependencyManagement>&lt;!--管理依赖版本号，但是不直接引入依赖包-->&lt;/dependencyManagement> &lt;modules>&lt;/modules> &lt;properties>&lt;/properties> &lt;!--build：构建项目目录结构和管理的插件--> &lt;build>&lt;/build> &lt;reporting>&lt;/reporting> &lt;!--project information：--> &lt;name>&lt;/name> &lt;description>&lt;/description> &lt;url>&lt;/url> &lt;inceptionYear>&lt;/inceptionYear> &lt;license>&lt;/license> &lt;organization>&lt;/organization> &lt;developers>&lt;/developers> &lt;contributors>&lt;/contributors> &lt;!--environment设置：--> &lt;issueManagement>&lt;/issueManagement> &lt;ciManagement>&lt;/ciManagement> &lt;mailingLists>&lt;/mailingLists> &lt;scm>&lt;!--软件配置管理-->&lt;/scm> &lt;prerequisites>&lt;/prerequisites> &lt;repositories>&lt;/repositories> &lt;pluginRepositories>&lt;/pluginRepositories> &lt;distributionManagement>&lt;/distributionManagement> &lt;profiles>&lt;/profiles> &lt;/project> settings.xml解析&lt;!---->&lt;>&lt;!---->&lt;/> &lt;!--根元素是settings，后接全局命名空间xmlns以及其它命名空间--> &lt;settings xmlns=\"aaa\" xmlns:xsi=\"bbb\" xsi:schemaLocation=\"ccc\"> &lt;localRepository 本地仓库路径/> &lt;interactiveMode true：与用户交互，false：不与用户交互，默认为true/> &lt;usePluginRegistry true：使用$&#123;user.home&#125;\\.m2\\plugin-registry.xml路径管理插件版本，默认false/> &lt;offline true:在离线模式下构建系统/> &lt;pluginGroups/> &lt;servers/> &lt;mirrors/> &lt;proxies/> &lt;profiles/> &lt;activeProfiles/> &lt;/settings> IDEA基本概念 .idea：存放项目的配置信息，包括历史记录，版本控制信息等 .iml: 代码注解、jar依赖的索引文件 对IDEA project structure的理解 导入或打开某个项目时,要打开跟.idea文件并列的那个项目,否则projectstructure报错 对IDEA maven工具中各选项的理解 ODL基本概念 ODL的总体架构改变的话，升第一个版本号，集成并更新功能，正式发布一个版本升第二个版本号，只是在某个正式发布版本的基础上修改bug，升第三个版本号 生成的项目骨架只有yang和md-sal的基础功能，不含任何业务 ,要增加features才能连接mininet blueprintblueprint是OSGi框架的一部分,使用xml,管理模块的加载、依赖、配置等(blueprint的配置介绍) 标准buleprint的标签: 元素 作用 bean 描述创建Java实例的元素，可以指定实例初始化的类名，构造方法，构造方法的入参及属性 reference 通过接口名引用一个OSGi service，可以指定一个特定的属性过滤器 reference-list 通过接口名引用多个 OSGi services ，可以指定一个特定的属性过滤器 service 把bean发布为OSGi service property 属性? argument 拓展ODL的XML配置语法,可以为某节点增加可选节点 &lt;!--根元素是blueprint,元素可以是标准元素也可以是封闭元素--> &lt;blueprint xmlns=命名空间 xmlns:xx=前缀 属性=属性 > &lt;bean id=\"provider\" class=\"networkGroup.impl.HelloworldProvider\" init-method=\"init\" destroy-method=\"close\"> &lt;argument ref=\"dataBroker\" /> &lt;/bean> &lt;reference id=\"dataBroker\" interface=\"org.opendaylight.controller.md.sal.binding.api.DataBroker\" odl:type=\"default\" /> &lt;service ref=\"domRpcRouter\" odl:type=\"default\"> &lt;interfaces> &lt;value>org.opendaylight.controller.md.sal.binding.api.DataBroker&lt;/value> &lt;value>org.opendaylight.controller.md.sal.binding.api.DataBroker&lt;/value> &lt;/interfaces> &lt;/service> &lt;service ref = \"domMountPointService\" interface=\"org.opendaylight.controller.md.sal.binding.api.DataBroker\" odl:type=\"default\"/> &lt;/blueprint> ODL对blueprint进行了拓展controller&#x2F;opendaylight&#x2F;blueprint: 元素 作用 odl:type 对于一个接口有多个实现的，odl:type可以用来确定某个具体实现 odl:rpc-implementation Global RPC注册 odl:routed-rpc-implementation Routed RPC的注册 odl:rpc-service Global RPC和Routed RPC的获取 odl:notification-listener NotificationListenser的注册,订阅者 odl:clustered-app-config 通过ODL的datastore实现集群内的全局配置,比较复杂 odl:default-config ? &lt;service ref=\"domRpcRouter\" odl:type=\"default\"> &lt;odl:rpc-implementation ref=\"fooRpcService\"/> &lt;odl:routed-rpc-implementation id=\"fooRoutedRpcServiceReg\" ref=\"fooRoutedRpcService\"/> &lt;odl:rpc-service id=\"fooRpcService\" interface=\"org.opendaylight.app.FooRpcService\"/> &lt;odl:notification-listener ref=\"fooListener\"/> &lt;odl:clustered-app-config id=\"myConfig\" binding-class=\"org.opendaylight.yang.gen.v1.urn.opendaylight.myapp.config.rev160624.MyConfig\"> &lt;/odl:clustered-app-config> blueprint配置要点: 配置注入的变量名在类定义中，首字母一定要小写，不能大写！！ 使用blueprint配置后，pom中不能有Bundle-Activator配置 两个Blueprint配置文件中的服务不能相互依赖 netty netty in action 推荐阅读 karaf 基本命令: //安装features feature:install odl-restconf odl-l2switch-switch-ui //如果要重新安装feature，请logout退出，清空安装目录下的data文件夹，再./karaf clean //善用TAB键补足命令 //搜索关键字op feature:list|grep op bundle:list|grep op /**查看日志*/ ld /**查找出错的日志*/ lde /**查看服务列表并索引关键字*/ service:list|grep xx 基本操作操作系统基本操作 查看ubuntu虚拟机防火墙是否开启: sudo ufw status //未开启 Status: inactive 查看ARP /*查看arp缓存*/ arp -a /*清空arp缓存*/ arp -d 查找某端口是否被监听 /**win11 cmd*/ netstat -an | findstr 6633 /**其他,待验证*/ netstat -an | grep 6633 DNS:公用DNS服务器:114.114.114.114&#x2F;223.5.5.5 /**进行DNS查询*/ nslookup /**查看DNS缓存*/ ipconfig /displayDNS /**清空DNS缓存*/ ipconfig/flushDNS VMware VMware虚拟机网络模式介绍 VMware自身有三块虚拟网卡，分别对应三种网卡模式： 安装 VMware会在宿主机形成两种网卡，VMware Network Adapter VMnet1和VMware Network Adapter VMnet8，由于本机还安装了VirtualBox以及微软的一些服务，ipconfig查出来的信息有时不叫这两个名字，有可能叫本地连接* 1只要按规则配置能用就不用管 桥接模式：VMWare虚拟机的网卡和宿主机的物理网卡都连接在虚拟交换机VMent0上，因此虚拟机网卡和宿主机网卡需要在同一网段才能通信，如果有多个虚拟机，它们相当于多个和宿主机平等的主机真实的接入VMent0 NAT模式:NAT模式下主机更像是虚拟机们的路由器,理解为主机是虚拟机的”上级”，NAT模式下的虚拟机时通过真实宿主机的ip访问外网 仅主机模式：仅主机模式下的虚拟机不具有联网能力，只能和宿主机通信 总结： 模式 特点 用途 桥接 虚拟机和宿主机都有独立的IP，处于平等地位接在虚拟交换机上，需要位于同网段才能通信 实验最常使用的配置模式，在许多场合下保持虚拟机、宿主机互相ping通即可 仅主机 无论虚拟机IP怎么配，其本身不能上网，仅能和宿主机通信 辅助模式，和桥接模式配合让虚拟机、宿主机ping通 NAT 宿主机相当于虚拟机的上级，虚拟机使用宿主机的IP上网 一般不使用，使用虚拟机工作的时候最方便，不用额外配置虚拟机网卡 常用配置网卡命令: //虚拟机配置ip方式 //1.进入系统配置文件 vim /etc/network/interfaces //2. 编辑网卡信息 //只开桥接网卡,静态ip写死 # interfaces(5) file used by ifup(8) and ifdown(8) auto lo iface lo inet loopback #auto ens38 #iface ens38 inet dhcp #iface ens38 inet static #address 171.10.0.17 #netmask 255.255.255.0 auto ens33 iface ens33 inet static address 192.168.0.11 netmask 255.255.255.0 //3.配置网段后重启网络服务,可ping同宿主机 sudo service networking restart //4.也可以用ifconfig,一般是单次生效 //配某网卡的 ip、掩码 ifconfig eth1 192.168.x.x netmask 255.255.255.0 //配网关 route add default gw 192.168.x.254 交换机 zhbit:先配置dpid再起控制器. /**内:22*/ telnet xx.xx.2.207 2300 loongson login: zhbit password: zhbit [zhbit@loongson ~]$ su password:zhbit [root@loongson application]# [root@loongson application]#export LD_LIBRARY_PATH=$LD_LIBRARY_PATH/mnt/application [root@loongson application]#./ovs-vsctl set bridge gcjh other-config:datapath-id=0000000000000016 [root@loongson application]# [root@loongson application]# 查看IGMP: show running//是否有snooping","categories":[{"name":"工具","slug":"工具","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7/"}],"tags":[{"name":"Utils","slug":"Utils","permalink":"http://example.com/tags/Utils/"}]},{"title":"YANG语言","slug":"YANG语言","date":"2022-08-09T10:48:22.389Z","updated":"2022-10-19T06:57:23.731Z","comments":true,"path":"2022/08/09/YANG语言/","link":"","permalink":"http://example.com/2022/08/09/YANG%E8%AF%AD%E8%A8%80/","excerpt":"​ 本文记录了学习SDN过程中涉及的YANG语言的知识点,以及ODL是如何使用YANG语言的.","text":"​ 本文记录了学习SDN过程中涉及的YANG语言的知识点,以及ODL是如何使用YANG语言的. 参考文献 RFC6020 - YANG语言标准中文 ODL技术内幕：架构设计与实现原理 Restful和Restconf REST（Representational State Transfer，表述性状态转移）是一种软件设计风格，不是一个标准，许多web是基于REST风格设计的。（1.资源静态，动作清晰；2.无状态设计；3.前后端分离API；） Restful接口是遵循REST设计风格的接口，没有标准要求； Restconf接口是既遵循REST设计风格，又遵循IETF制定的RFC8040标准的接口，有明确的定义和设计规范，基于HTTP协议，用于访问YANG语言定义的数据。比Netconf语言简洁、灵活。 YANG基础概念 schema tree:模式树,data tree:数据树; 专门用于描述数据的语言; YANG语言使用module\\submodule构建数据模型; 树形结构; ODL用YANG抽象数据模型,包括项目YANGTools等; 基础语法注释Comments 单行注释开始于“&#x2F;&#x2F;”，结束于本行。块注释开始于“&#x2F;*”，结束于“ *&#x2F;”,跟C++风格一样 定义module和submodule 一个module能包含任意数量的submodules，但是每个submodule只能属于一个module moudle还包含一些命名空间、前缀 //这些是module的基本信息,包括import的其它module,本module的版本、修改时间、简称的前缀等 module sal-flow &#123; namespace \"urn:opendaylight:flow:service\"; prefix flow; import yang-ext &#123;prefix ext; revision-date \"2013-07-09\";&#125; import opendaylight-inventory &#123;prefix inv;revision-date \"2013-08-19\";&#125; import opendaylight-flow-types &#123;prefix types;revision-date \"2013-10-26\";&#125; import opendaylight-group-types &#123;prefix group-type;revision-date \"2013-10-18\";&#125; import opendaylight-meter-types &#123;prefix meter-type;revision-date \"2013-09-18\";&#125; import flow-capable-transaction &#123;prefix tr; revision-date \"2015-03-04\";&#125; import flow-errors &#123;prefix error; revision-date \"2013-11-16\";&#125; description \"Openflow flow management.\"; revision \"2013-08-19\" &#123; description \"Initial revision of flow service\"; &#125; 枚举类型enumeration//例子1 type enumeration &#123; enum 10m; enum 100m; enum auto; &#125; //例子2 leaf echo-result &#123; type enumeration &#123; enum \"reachable\" &#123; value 0; description \"Received reply\"; &#125; enum \"unreachable\" &#123; value 1; description \"No reply during timeout\"; &#125; enum \"error\" &#123; value 2; description \"Error happened\"; &#125; &#125; description \"Result types\"; &#125; YANG四种节点类型 leaf：只能包含一个值，没有子节点； //一个名字叫host-name的leaf类型的节点 //节点包含string类型的数据 //描述信息是\"Hostname for this system\" leaf host-name &#123; type string; //必选 description \"Hostname for this system\"; &#125; leaf-list：一系列的leaf节点； //一系列leaf节点,这些节点都是用来domain-search的 //节点都包含string类型数据 //相当于数组 leaf-list domain-search &#123; type string; description \"List of domain names to search\"; &#125; container:没有值,专门用于把相关的节点归纳到一个subtree下面,可以包括任何类型\\任何数量子节点: //container类型的system节点包含container类型的login节点 //container类型的login节点把leaf类型 message节点组成了一棵子树 container system &#123; container login &#123; leaf message &#123; type string; description\"Message given at start of login session\"; &#125; &#125; &#125; list:由一个key的leaf节点唯一确定,能定义多种key leafs,能包含任意类型\\任意数目子节点: //名为user的list,由名为name的leaf节点唯一确定 //user里面还包括其他leaf list user &#123; key \"name\"; leaf name &#123; type string; &#125; leaf full-name &#123; type string; &#125; leaf class &#123; type string; &#125; &#125; 上述四种节点可以组成简单的示例module: // Contents of \\\"acme-system.yang\\\" module acme-system &#123; namespace \\\"http://acme.example.com/system\\\"; prefix \\\"acme\\\"; organization \\\"ACME Inc.\\\"; contact \\\"joe@acme.example.com\\\"; description \\\"The module for entities implementing the ACME system.\\\"; revision 2007-06-09 &#123; description \\\"Initial revision.\\\"; &#125; container system &#123; leaf host-name &#123; type string; description \\\"Hostname for this system\\\"; &#125; leaf-list domain-search &#123; type string; description \\\"List of domain names to search\\\"; &#125; container login &#123; leaf message &#123; type string; description\"Message given at start of login session\\\"; &#125; list user &#123; key \\\"name\\\"; leaf name &#123; type string; &#125; leaf full-name &#123; type string; &#125; leaf class &#123; type string; &#125; &#125; &#125; &#125; &#125; YANG定义RPC(Remote Procedure Call) 定义操作名字，输入参数，和输出参数: //定义远程调用activate-software-image //输入的一个string类型的 image-name //期望得到一个string类型的输出status rpc activate-software-image &#123; input &#123; leaf image-name &#123; type string; &#125; &#125; output &#123; leaf status &#123; type string; &#125; &#125; &#125; Helloworld.yang被解读为： //helloworld模块中定义了一次名为hello-world的rpc调用 //输入是string类型的name //输出是string类型的greeting //能够与Postman请求的结果对应上 module helloworld &#123; yang-version 1.1; namespace \"urn:opendaylight:params:xml:ns:yang:helloworld\"; prefix \"helloworld\"; revision \"2017-08-30\" &#123; // TODO change revision to date of model creation description \"Initial revision of helloworld model\"; &#125; rpc hello-world &#123; input &#123; leaf name &#123; type string; &#125; &#125; output &#123; leaf greeting &#123; type string; &#125; &#125; &#125; Routed RPC:一定要有input字段,一定要有routed字段,routed字段的根本类型必须是instance-identifier /*yang定义*/ typedef person-ref&#123; type instance-identifier; &#125; identity person-context&#123; description \"ccc\"; &#125; /*定义关键字context-reference,*/ extension \"context-reference\"&#123; argument \"context-type\"; &#125; rpc buy-car&#123; input&#123; leaf person&#123; /**下面两句就是routed字段*/ ext:context-reference \"person-context\"; type person-ref; ... &#125; &#125; &#125; /*注册*/ &lt;odl:routed-rpc-implementation id=\"xxx\" ref=\"zzz\"/> &lt;bean id=\"peopleProvider\" class=\"org.opendaylight.controller.clustering.it.provider.PeopleProvider\"> &lt;property name=\"dataProviser\" ref=\"dataBroker\"/> &lt;property name=\"rpcRegistration\" ref=\"carPurchaseRpcReg\"/> &lt;/bean> /*需要调用rpcRegistration.registerPath(xx.class,personId)*/ YANG定义Notification notifaction是误拼,写文件时千万注意 notification的定义和container\\grouping差不多,不像RPC中有input和output,应该是跟notification的运行机制有关系 notification flow-added &#123; status deprecated; uses tr:transaction-metadata; leaf flow-ref &#123; type types:flow-ref; &#125; uses node-flow; uses tr:transaction-aware; &#125; YANG自定义新类型typedef typedef声明定义了一个新的type， 该自定义type可以在module内部，包含该module的modules或submodules，以及导入该module的其它modules使用 // flow-table-ref 是定义的新类型的名字 typedef flow-table-ref &#123; description \"Openflow table identifier\"; type instance-identifier; // instance-identifier是YANG的基本类型:References a data tree node &#125; 例如inet:port-number\\inet:ip-address都是自定义的类型 可重用节点集合Grouping grouping声明了一个可重用的集合,定以后在引用的位置通过”uses”实例化 //定义名为node-flow-removed的 grouping //里面添加了两个leaf // grouping node-flow-removed &#123; description \"Flow removed message structure.\"; leaf node &#123; // TODO:: replace with inv:node-context-ref ext:context-reference \"inv:node-context\"; type inv:node-ref; &#125; leaf flow-table &#123; type flow-table-ref; &#125; uses types:flow-mod-removed; &#125; //在container中引用grouping container peer &#123; container destination &#123; uses node-flow-removed; &#125; &#125; grouping可以在引用时被重新定义 uses只有一个参数,应该是grouping的名字, //标准用法 type是其他yang文件的简称,以前缀的形式出现 uses types:flow; //参数带双引号是什么意思?grouping名字可以带双引号? uses \"inv:node-context-ref\"; status声明 “status”声明的参数是一个字符串，是“current”，“deprecated”或者“obsolete”中的一个 “current”意味着该定义在当前是有效的 “deprecated”表示该定义已经被废弃，不过保证在暂时在后续的实现中支持该定义，以保证向前兼容 “obsolete”意味着这个定义已经被完全废弃，不应该再使用了 choice与case “choice”和”case”用于声明互不相容不能同时出现的节点，”choice”声明包含了多个”case” 每个”case”声明都可能包含多个节点，但是每个节点都应该只在一个”case”中出现 //可以理解为object-reference中有三个选项 //这三个选项只能选一个,不能同时生效 grouping node-error-reference &#123; description \"Error message binding - to which source type the error belongs.\"; choice object-reference &#123; case flow-ref&#123; leaf flow-ref &#123; type types:flow-ref; &#125; &#125; case group-ref&#123; leaf group-ref &#123; type group-type:group-ref; &#125; &#125; case meter-ref&#123; leaf meter-ref &#123; type meter-type:meter-ref; &#125; &#125; &#125; &#125; include与import include用于引用其他submodule定义的数据 import用于引入其他module定义的数据 include acme-types; import yang-ext &#123;prefix ext; revision-date \"2013-07-09\";&#125; 扩展数据模型(augment) 允许一个模块将额外的节点插入到数据模型中，包括当前的module(以及它的submodule)或者一个外部的module augment定义了在数据模型树形结构中，新的节点插入的位置,when声明了新节点生效的时间。 /*当该node的user的class不等于wheel的时候,把uid节点插到augment声明的位置*/ augment /system/login/user &#123; when \"class != 'wheel\"; leaf uid &#123; type uint16 &#123; range \"1000 .. 30000\"; &#125; &#125; &#125; 语言扩展extension 使用extension可以定义新的关键字,使用的时候需要在引入新关键字的位置带上定义新关键字的module名字 identity声明 用于定义一个新的，全局唯一的，抽象的，没有特定类型的identity 目的就是对外宣示它的名字，语义以及存在,既能够从头开始定义，也能够从一个base identity处继承 identity的参数是一个identifier，就是这个identity的名字 module crypto-base &#123; namespace \"http://example.com/crypto-base\"; prefix \"crypto\"; identity crypto-alg &#123; description \"Base identity from which all crypto algorithms are derived.\"; &#125; &#125; module des &#123; namespace \"http://example.com/des\"; prefix \"des\"; import \"crypto-base\" &#123; prefix \"crypto\"; &#125; identity des &#123; base \"crypto:crypto-alg\"; description \"DES crypto algorithm\"; &#125; identity des3 &#123; base \"crypto:crypto-alg\"; description \"Triple DES crypto algorithm\"; &#125; &#125; YANG在ODL中的实现元素命名QName（Qualified Name，限定名） 来源于XML，格式是命名空间namespace：元素名localName，例：xsl:template ODL类似于XML，但多了revision字段，即namespace、localName和revision（修订版本），其中namespace和revision标识一个YANGmodule，可以分为locallocalName和QNameModule ODL在org.opendaylight.yangtools.yang.common中定义 QName由QName、QNameModule与Revision类组成 QName的比较、创建…. 数据树的索引YangInstanceIdentifier YANG中有instance-identifier用来唯一标识数据树中某个节点,ODL用YangInstanceIdentifier类实现 是一个分层的、基于内容的、唯一的标识符，用来对数据树中数据项的寻址，代表了数据树中某个节点的路径 语法格式使用的是XPath的简化格式的子集,ODL用Path接口表示,org.opendaylight.yangtools.concepts.Path YangInstanceIdentifier类实现Path接口,可以说YangInstance-Identifier类就是表示了数据树中的节点访问路径的定义,org.opendaylight.yangtools.yang.data.api.YangInstanceIdentifier YangInstanceIdentifier由PathArgument(路径的参数)组成,一组有序的PathArgument列表构成一条访问路径 YangInstanceIdentifier的比较、创建…. 数据节点抽象定义NomalizedNode NormalizedNode类作为所有数据节点的基础抽象,即定义一个通用的接口来统一表示上述YANG节点类型","categories":[{"name":"SDN","slug":"SDN","permalink":"http://example.com/categories/SDN/"}],"tags":[{"name":"YANG","slug":"YANG","permalink":"http://example.com/tags/YANG/"}]}],"categories":[{"name":"SDN","slug":"SDN","permalink":"http://example.com/categories/SDN/"},{"name":"工具","slug":"工具","permalink":"http://example.com/categories/%E5%B7%A5%E5%85%B7/"}],"tags":[{"name":"拓扑发现","slug":"拓扑发现","permalink":"http://example.com/tags/%E6%8B%93%E6%89%91%E5%8F%91%E7%8E%B0/"},{"name":"开发日志","slug":"开发日志","permalink":"http://example.com/tags/%E5%BC%80%E5%8F%91%E6%97%A5%E5%BF%97/"},{"name":"初始化","slug":"初始化","permalink":"http://example.com/tags/%E5%88%9D%E5%A7%8B%E5%8C%96/"},{"name":"ARP","slug":"ARP","permalink":"http://example.com/tags/ARP/"},{"name":"ODL","slug":"ODL","permalink":"http://example.com/tags/ODL/"},{"name":"Openflowplugin","slug":"Openflowplugin","permalink":"http://example.com/tags/Openflowplugin/"},{"name":"L2switch","slug":"L2switch","permalink":"http://example.com/tags/L2switch/"},{"name":"Bug","slug":"Bug","permalink":"http://example.com/tags/Bug/"},{"name":"Utils","slug":"Utils","permalink":"http://example.com/tags/Utils/"},{"name":"YANG","slug":"YANG","permalink":"http://example.com/tags/YANG/"}]}